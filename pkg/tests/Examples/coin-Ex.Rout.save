
R Under development (unstable) (2014-08-19 r66437) -- "Unsuffered Consequences"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "coin"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> options(pager = "console")
> library('coin')
Loading required package: survival
Loading required package: splines
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("CWD")
> ### * CWD
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: CWD
> ### Title: Coarse Woody Debris Data
> ### Aliases: CWD
> ### Keywords: datasets
> 
> ### ** Examples
> 
> 
>   data("CWD")
>   CWD[1:6] <- 100 * CWD[1:6] # scaling (to avoid warning)
>   maxstat_test(sample2 + sample3 + sample4 +
+                sample6 + sample7 + sample8 ~ trend, data = CWD,
+                distribution = approximate(1e5))

	Approximative Generalized Maximally Selected Statistics

data:  sample2, sample3, sample4, sample6, sample7, sample8 by trend
maxT = 3.0793, p-value = 0.0082
alternative hypothesis: two.sided
sample estimates:
  "best" cutpoint: <= 71

> 
> 
> 
> 
> cleanEx()
> nameEx("ContingencyTests")
> ### * ContingencyTests
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: ContingencyTests
> ### Title: Independence in Three-Way Contingency Tables
> ### Aliases: chisq_test chisq_test.formula chisq_test.table
> ###   chisq_test.IndependenceProblem cmh_test cmh_test.formula
> ###   cmh_test.table cmh_test.IndependenceProblem lbl_test lbl_test.formula
> ###   lbl_test.table lbl_test.IndependenceProblem
> ### Keywords: htest
> 
> ### ** Examples
> 
>   ### Example from Davis (1986, p. 140)
>   davis <- matrix(c(3,  6,
+                     2, 19),
+                   nrow = 2, byrow = TRUE)
> 
>   ### Asymptotic Pearson chi-squared test
>   (ct <- chisq_test(as.table(davis)))

	Asymptotic Pearson's Chi-Squared Test

data:  Var2 by Var1 (A, B)
chi-squared = 2.5714, df = 1, p-value = 0.1088

> 
>   ### Approximate (Monte Carlo) Pearson chi-squared test
>   ct <- chisq_test(as.table(davis), distribution = approximate(B = 10000))
>   pvalue(ct)          # standard p-value
[1] 0.2849
99 percent confidence interval:
 0.2733285 0.2966774 

>   midpvalue(ct)       # mid-p-value
[1] 0.151
99 percent confidence interval:
 0.1419433 0.1603887 

>   pvalue_interval(ct) # p-value interval
   p_0    p_1 
0.0171 0.2849 
> 
>   ### Exact Pearson chi-squared test
>   ### (Disagrees with Fisher's exact test, see Davis, 1986)
>   ct <- chisq_test(as.table(davis), distribution = "exact")
>   pvalue(ct)          # standard p-value
[1] 0.2860301
>   midpvalue(ct)       # mid-p-value
[1] 0.1527409
>   pvalue_interval(ct) # p-value interval
       p_0        p_1 
0.01945181 0.28603006 
>   fisher.test(davis)

	Fisher's Exact Test for Count Data

data:  davis
p-value = 0.1432
alternative hypothesis: true odds ratio is not equal to 1
95 percent confidence interval:
  0.410317 65.723900
sample estimates:
odds ratio 
  4.462735 

> 
> 
>   ### Laryngeal cancer
>   ### Agresti (2002, p. 107, Tab. 3.13)
>   cancer <- matrix(c(21, 2,
+                      15, 3),
+                    nrow = 2, byrow = TRUE,
+                    dimnames = list(Treatment = c("Surgery", "Radiation"),
+                                    Cancer = c("Controlled","Not Controlled")))
> 
>   ### Exact Pearson chi-squared test
>   ### (Agrees with Fishers's exact test, see Agresti, 2002, p. 108, Tab 3.14)
>   (ct <- chisq_test(as.table(cancer), distribution = "exact"))

	Exact Pearson's Chi-Squared Test

data:  Cancer by Treatment (Surgery, Radiation)
chi-squared = 0.5992, p-value = 0.6384

>   midpvalue(ct)       # mid-p-value
[1] 0.5006832
>   pvalue_interval(ct) # p-value interval
      p_0       p_1 
0.3629407 0.6384258 
>   fisher.test(cancer)

	Fisher's Exact Test for Count Data

data:  cancer
p-value = 0.6384
alternative hypothesis: true odds ratio is not equal to 1
95 percent confidence interval:
  0.2089115 27.5538747
sample estimates:
odds ratio 
  2.061731 

> 
> 
>   ### jobsatisfaction, for females only
>   chisq_test(as.table(jobsatisfaction[, , "Female"]),
+       distribution = approximate(B = 10000))

	Approximative Pearson's Chi-Squared Test

data:  Job.Satisfaction by
	 Income (<5000, 5000-15000, 15000-25000, >25000)
chi-squared = 6.8203, p-value = 0.6834

> 
>   ### both Income and Job.Satisfaction unordered
>   cmh_test(jobsatisfaction)

	Asymptotic Generalized Cochran-Mantel-Haenszel Test

data:  Job.Satisfaction by
	 Income (<5000, 5000-15000, 15000-25000, >25000) 
	 stratified by Gender
chi-squared = 10.2001, df = 9, p-value = 0.3345

> 
>   ### both Income and Job.Satisfaction ordered, default scores
>   lbl_test(jobsatisfaction)

	Asymptotic Linear-by-Linear Association Test

data:  Job.Satisfaction (ordered) by
	 Income (<5000 < 5000-15000 < 15000-25000 < >25000) 
	 stratified by Gender
Z = 2.5736, p-value = 0.01006
alternative hypothesis: two.sided

> 
>   ### both Income and Job.Satisfaction ordered, alternative scores
>   lbl_test(jobsatisfaction, scores = list(Job.Satisfaction = c(1, 3, 4, 5),
+                                           Income = c(3, 10, 20, 35)))

	Asymptotic Linear-by-Linear Association Test

data:  Job.Satisfaction (ordered) by
	 Income (<5000 < 5000-15000 < 15000-25000 < >25000) 
	 stratified by Gender
Z = 2.4812, p-value = 0.01309
alternative hypothesis: two.sided

> 
>   ### the same, null distribution approximated
>   cmh_test(jobsatisfaction, scores = list(Job.Satisfaction = c(1, 3, 4, 5),
+                                           Income = c(3, 10, 20, 35)),
+            distribution = approximate(B = 10000))

	Approximative Linear-by-Linear Association Test

data:  Job.Satisfaction (ordered) by
	 Income (<5000 < 5000-15000 < 15000-25000 < >25000) 
	 stratified by Gender
Z = 2.4812, p-value = 0.015
alternative hypothesis: two.sided

> 
> 
>   ### Smoking and HDL cholesterin status
>   ### (from Jeong, Jhun and Kim, 2005, CSDA 48, 623-631, Table 2)
>   smokingHDL <- as.table(
+       matrix(c(15,  8, 11,  5,
+                 3,  4,  6,  1,
+                 6,  7, 15, 11,
+                 1,  2,  3,  5), ncol = 4,
+              dimnames = list(smoking = c("none", "< 5", "< 10", ">=10"),
+                              HDL = c("normal", "low", "borderline", "abnormal"))
+   ))
>   ### use interval mid-points as scores for smoking
>   lbl_test(smokingHDL, scores = list(smoking = c(0, 2.5, 7.5, 15)))

	Asymptotic Linear-by-Linear Association Test

data:  HDL (ordered) by smoking (none < < 5 < < 10 < >=10)
Z = 3.1394, p-value = 0.001693
alternative hypothesis: two.sided

> 
> 
>   ### Cochran-Armitage trend test for proportions
>   ### Lung tumors in female mice exposed to 1,2-dichloroethane
>   ### Encyclopedia of Biostatistics (Armitage & Colton, 1998),
>   ### Chapter Trend Test for Counts and Proportions, page 4578, Table 2
>   lungtumor <- data.frame(dose = rep(c(0, 1, 2), c(40, 50, 48)),
+                           tumor = c(rep(c(0, 1), c(38, 2)),
+                                     rep(c(0, 1), c(43, 7)),
+                                     rep(c(0, 1), c(33, 15))))
>   table(lungtumor$dose, lungtumor$tumor)
   
     0  1
  0 38  2
  1 43  7
  2 33 15
> 
>   ### Cochran-Armitage test (permutation equivalent to correlation
>   ### between dose and tumor), cf. Table 2 for results
>   independence_test(tumor ~ dose, data = lungtumor, teststat = "quadratic")

	Asymptotic General Independence Test

data:  tumor by dose
chi-squared = 10.6381, df = 1, p-value = 0.001108

> 
>   ### linear-by-linear association test with scores 0, 1, 2
>   ### is identical to Cochran-Armitage test
>   lungtumor$dose <- ordered(lungtumor$dose)
>   independence_test(tumor ~ dose, data = lungtumor, teststat = "quadratic",
+                     scores = list(dose = c(0, 1, 2)))

	Asymptotic General Independence Test

data:  tumor by dose (0 < 1 < 2)
chi-squared = 10.6381, df = 1, p-value = 0.001108

> 
> 
> 
> 
> cleanEx()
> nameEx("CorrelationTests")
> ### * CorrelationTests
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: CorrelationTests
> ### Title: Correlation Tests
> ### Aliases: spearman_test spearman_test.formula
> ###   spearman_test.IndependenceProblem fisyat_test fisyat_test.formula
> ###   fisyat_test.IndependenceProblem quadrant_test quadrant_test.formula
> ###   quadrant_test.IndependenceProblem koziol_test koziol_test.formula
> ###   koziol_test.IndependenceProblem
> ### Keywords: htest
> 
> ### ** Examples
> 
> 
>   spearman_test(CONT ~ INTG, data = USJudgeRatings)

	Asymptotic Spearman Correlation Test

data:  CONT by INTG
Z = -1.1437, p-value = 0.2527
alternative hypothesis: true rho is not equal to 0

> 
>   fisyat_test(CONT ~ INTG, data = USJudgeRatings)

	Asymptotic Fisher-Yates Correlation Test

data:  CONT by INTG
Z = -0.8248, p-value = 0.4095
alternative hypothesis: true rho is not equal to 0

> 
>   quadrant_test(CONT ~ INTG, data = USJudgeRatings)

	Asymptotic Quadrant Test

data:  CONT by INTG
Z = -1.0944, p-value = 0.2738
alternative hypothesis: true rho is not equal to 0

> 
>   koziol_test(CONT ~ INTG, data = USJudgeRatings)

	Asymptotic Koziol-Nemec Test

data:  CONT by INTG
Z = -1.292, p-value = 0.1964
alternative hypothesis: true rho is not equal to 0

> 
> 
> 
> 
> cleanEx()
> nameEx("Distribution")
> ### * Distribution
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Distribution
> ### Title: Specification of the Reference Distribution
> ### Aliases: asymptotic approximate exact
> ### Keywords: htest
> 
> ### ** Examples
> 
> ## Approximate (Monte Carlo) Cochran-Mantel-Haenszel test
> 
> ## Serial operation
> set.seed(123)
> cmh_test(disease ~ smoking | gender, data = alzheimer,
+          distribution = approximate(B = 100000))

	Approximative Generalized Cochran-Mantel-Haenszel Test

data:  disease by
	 smoking (None, <10, 10-20, >20) 
	 stratified by gender
chi-squared = 23.3163, p-value = 0.00052

> 
> ## Not run: 
> ##D ## Multicore with 8 processes (not for MS Windows)
> ##D set.seed(123, kind = "L'Ecuyer-CMRG")
> ##D cmh_test(disease ~ smoking | gender, data = alzheimer,
> ##D          distribution = approximate(B = 100000,
> ##D                                     parallel = "multicore", ncpus = 8))
> ##D 
> ##D ## Automatic PSOCK cluster with 4 processes
> ##D set.seed(123, kind = "L'Ecuyer-CMRG")
> ##D cmh_test(disease ~ smoking | gender, data = alzheimer,
> ##D          distribution = approximate(B = 100000,
> ##D                                     parallel = "snow", ncpus = 4))
> ##D 
> ##D ## Registered FORK cluster with 12 processes (not for MS Windows)
> ##D fork12 <- parallel::makeCluster(12, "FORK") # set-up cluster
> ##D parallel::setDefaultCluster(fork12) # register default cluster
> ##D set.seed(123, kind = "L'Ecuyer-CMRG")
> ##D cmh_test(disease ~ smoking | gender, data = alzheimer,
> ##D          distribution = approximate(B = 100000,
> ##D                                     parallel = "snow"))
> ##D parallel::stopCluster(fork12) # clean-up
> ##D 
> ##D ## User-specified PSOCK cluster with 8 processes
> ##D psock8 <- parallel::makeCluster(8, "PSOCK") # set-up cluster
> ##D set.seed(123, kind = "L'Ecuyer-CMRG")
> ##D cmh_test(disease ~ smoking | gender, data = alzheimer,
> ##D          distribution = approximate(B = 100000,
> ##D                                     parallel = "snow", cl = psock8))
> ##D parallel::stopCluster(psock8) # clean-up
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("GTSG")
> ### * GTSG
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: GTSG
> ### Title: Gastrointestinal Tumor Study Group
> ### Aliases: GTSG
> ### Keywords: datasets
> 
> ### ** Examples
> 
>   ### plot Kaplan-Meier estimates
>   plot(survfit(Surv(time / (365.25 / 12), event) ~ group, data = GTSG),
+        lty = 1:2,
+        ylab = "% Survival", xlab = "Survival Time in Months")
>   legend("topright", lty = 1:2,
+          c("Chemotherapy+Radiation", "Chemotherapy"), bty = "n")
> 
>   ### logrank test
>   surv_test(Surv(time, event) ~ group, data = GTSG)

	Asymptotic 2-Sample Logrank Test

data:  Surv(time, event) by
	 group (Chemotherapy+Radiation, Chemotherapy)
Z = -1.1428, p-value = 0.2531
alternative hypothesis: true theta is not equal to 1

> 
>   ### Prentice test
>   surv_test(Surv(time, event) ~ group, data = GTSG,
+             type = "Prentice")

	Asymptotic 2-Sample Prentice Test

data:  Surv(time, event) by
	 group (Chemotherapy+Radiation, Chemotherapy)
Z = -2.1687, p-value = 0.03011
alternative hypothesis: true theta is not equal to 1

> 
>   ### testing against Weibull-type alternatives, see Moreau et al (1992)
>   moreau_weight <- function(time, n.risk, n.event)
+       1 + log(-log(cumprod(n.risk / (n.risk + n.event))))
> 
>   independence_test(Surv(time, event) ~ group, data = GTSG,
+                     ytrafo = function(data)
+                         trafo(data, surv_trafo = function(y)
+                             logrank_trafo(y, weight = moreau_weight)))

	Asymptotic General Independence Test

data:  Surv(time, event) by
	 group (Chemotherapy+Radiation, Chemotherapy)
Z = 2.4129, p-value = 0.01583
alternative hypothesis: two.sided

> 
>   ### testing against crossing-curve alternatives, see Shen & Le (2000)
>   shen_trafo <- function(x)
+       ansari_trafo(logrank_trafo(x, type = "Prentice"))
> 
>   independence_test(Surv(time, event) ~ group, data = GTSG,
+                     ytrafo = function(data)
+                         trafo(data, surv_trafo = shen_trafo))

	Asymptotic General Independence Test

data:  Surv(time, event) by
	 group (Chemotherapy+Radiation, Chemotherapy)
Z = -2.342, p-value = 0.01918
alternative hypothesis: two.sided

> 
> 
> 
> cleanEx()
> nameEx("IndependenceTest")
> ### * IndependenceTest
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: IndependenceTest
> ### Title: General Independence Tests
> ### Aliases: independence_test independence_test.formula
> ###   independence_test.table independence_test.IndependenceProblem
> ### Keywords: htest
> 
> ### ** Examples
> 
> 
>   ### independence of asat and group via normal scores test
>   independence_test(asat ~ group, data = asat,
+ 
+     ### exact null distribution
+     distribution = "exact",
+ 
+     ### one-sided test
+     alternative = "greater",
+ 
+     ### apply normal scores to asat$asat
+     ytrafo = function(data) trafo(data, numeric_trafo = normal_trafo),
+ 
+     ### indicator matrix of 1st level of group
+     xtrafo = function(data) trafo(data, factor_trafo = function(x)
+         matrix(x == levels(x)[1], ncol = 1))
+   )

	Exact General Independence Test

data:  asat by group (Compound, Control)
Z = 1.4269, p-value = 0.07809
alternative hypothesis: greater

> 
>   ### same as
>   normal_test(asat ~ group, data = asat, distribution = "exact",
+               alternative = "greater")

	Exact 2-Sample Normal Quantile (van der Waerden) Test

data:  asat by group (Compound, Control)
Z = 1.4269, p-value = 0.07809
alternative hypothesis: true mu is greater than 0

> 
> 
>   ### permutation test for paired observations
>   y1 <- c(1.83,  0.50,  1.62,  2.48, 1.68, 1.88, 1.55, 3.06, 1.30)
>   y2 <- c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29)
>   dta <- data.frame(y = c(y1, y2), x = gl(2, length(y1)),
+                     block = factor(rep(seq_along(y1), 2)))
>   independence_test(y ~ x | block, data = dta,
+                     distribution = "exact", alternative = "greater")

	Exact General Independence Test

data:  y by x (1, 2) 
	 stratified by block
Z = 2.1948, p-value = 0.01367
alternative hypothesis: greater

> 
>   ### alternatively: transform data and set 'paired = TRUE'
>   diff <- y1 - y2
>   y <- as.vector(rbind(abs(diff) * (diff >= 0), abs(diff) * (diff < 0)))
>   x <- factor(rep(0:1, length(diff)), labels = c("pos", "neg"))
>   block <- gl(length(diff), 2)
>   independence_test(y ~ x | block,
+                     distribution = "exact", alternative = "greater",
+                     paired = TRUE)

	Exact General Independence Test

data:  y by x (pos, neg) 
	 stratified by block
Z = 2.1948, p-value = 0.01367
alternative hypothesis: greater

> 
> 
>   ### if you are interested in the internals:
>   ## Not run: 
> ##D       browseURL(system.file("documentation", "html", "index.html",
> ##D                             package = "coin"))
> ##D   
> ## End(Not run)
> 
> 
> 
> 
> cleanEx()
> nameEx("LocationTests")
> ### * LocationTests
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: LocationTests
> ### Title: Independent Two- and K-Sample Location Tests
> ### Aliases: oneway_test oneway_test.formula
> ###   oneway_test.IndependenceProblem wilcox_test wilcox_test.formula
> ###   wilcox_test.IndependenceProblem kruskal_test kruskal_test.formula
> ###   kruskal_test.IndependenceProblem normal_test normal_test.formula
> ###   normal_test.IndependenceProblem median_test median_test.formula
> ###   median_test.IndependenceProblem savage_test savage_test.formula
> ###   savage_test.IndependenceProblem
> ### Keywords: htest
> 
> ### ** Examples
> 
>   ## Don't show: 
> options(useFancyQuotes = FALSE)
> ## End Don't show
>   ### Tritiated Water Diffusion Across Human Chorioamnion
>   ### Hollander & Wolfe (1999), Table 4.1, page 110
>   water_transfer <- data.frame(
+       pd = c(0.80, 0.83, 1.89, 1.04, 1.45, 1.38, 1.91, 1.64, 0.73, 1.46,
+              1.15, 0.88, 0.90, 0.74, 1.21),
+       age = factor(c(rep("At term", 10), rep("12-26 Weeks", 5))))
> 
>   ### Wilcoxon-Mann-Whitney test, cf. Hollander & Wolfe (1999), page 111
>   ### exact p-value and confidence interval for the difference in location
>   ### (At term - 12-26 Weeks)
>   wt <- wilcox_test(pd ~ age, data = water_transfer,
+                     distribution = "exact", conf.int = TRUE)
>   print(wt)

	Exact Wilcoxon-Mann-Whitney Test

data:  pd by age (12-26 Weeks, At term)
Z = -1.2247, p-value = 0.2544
alternative hypothesis: true mu is not equal to 0
95 percent confidence interval:
 -0.76  0.15
sample estimates:
difference in location 
                -0.305 

> 
>   ### extract observed Wilcoxon statistic, i.e, the sum of the
>   ### ranks for age = "12-26 Weeks"
>   statistic(wt, "linear")
              
12-26 Weeks 30
> 
>   ### its expectation
>   expectation(wt)
12-26 Weeks 
         40 
> 
>   ### and variance
>   covariance(wt)
            12-26 Weeks
12-26 Weeks    66.66667
> 
>   ### and the exact two-sided p-value
>   pvalue(wt)
[1] 0.2544123
> 
>   ### and, finally, the confidence interval
>   confint(wt)
95 percent confidence interval:
 -0.76  0.15 
sample estimates:
difference in location 
                -0.305 

> 
>   ### for two samples, Kruskal-Wallis' test is equivalent to the W-M-W test
>   kruskal_test(pd ~ age, data = water_transfer,
+                distribution = "exact")

	Exact Kruskal-Wallis Test

data:  pd by age (12-26 Weeks, At term)
chi-squared = 1.5, p-value = 0.2544

> 
>   ### Confidence interval for difference (12-26 Weeks - At term)
>   wilcox_test(pd ~ age, data = water_transfer,
+               xtrafo = function(data)
+                   trafo(data, factor_trafo = function(x)
+                       as.numeric(x == levels(x)[2])),
+               distribution = "exact", conf.int = TRUE)

	Exact Wilcoxon-Mann-Whitney Test

data:  pd by age (12-26 Weeks, At term)
Z = 1.2247, p-value = 0.2544
alternative hypothesis: true mu is not equal to 0
95 percent confidence interval:
 -0.15  0.76
sample estimates:
difference in location 
                 0.305 

> 
>   ### Permutation test, asymptotic p-value
>   oneway_test(pd ~ age, data = water_transfer)

	Asymptotic 2-Sample Permutation Test

data:  pd by age (12-26 Weeks, At term)
Z = -1.5225, p-value = 0.1279
alternative hypothesis: true mu is not equal to 0

> 
>   ### approximate p-value (with 99% confidence interval)
>   pvalue(oneway_test(pd ~ age, data = water_transfer,
+                      distribution = approximate(B = 9999)))
[1] 0.1311131
99 percent confidence interval:
 0.1225462 0.1400337 

>   ### exact p-value
>   pt <- oneway_test(pd ~ age, data = water_transfer, distribution = "exact")
>   pvalue(pt)
[1] 0.1318681
> 
>   ### plot density and distribution of the standardized test statistic
>   layout(matrix(1:2, nrow = 2))
>   s <- support(pt)
>   d <- sapply(s, function(x) dperm(pt, x))
>   p <- sapply(s, function(x) pperm(pt, x))
>   plot(s, d, type = "S", xlab = "Test Statistic", ylab = "Density")
>   plot(s, p, type = "S", xlab = "Test Statistic", ylab = "Cum. Probability")
>   layout(1)
> 
> 
>   ### Median test with different mid-scores
>   ex <- data.frame(y = c(3, 4, 8, 9, 1, 2, 5, 6, 7),
+                    x = factor(rep(c("no", "yes"), c(4, 5))))
> 
>   boxplot(y ~ x, data = ex)
> 
>   (mt1 <- median_test(y ~ x, data = ex, distribution = "exact"))

	Exact 2-Sample Median Test

data:  y by x (no, yes)
Z = 0.2828, p-value = 1
alternative hypothesis: true mu is not equal to 0

>   (mt2 <- median_test(y ~ x, data = ex, distribution = "exact",
+                       mid.score = "0.5"))

	Exact 2-Sample Median Test

data:  y by x (no, yes)
Z = 0, p-value = 1
alternative hypothesis: true mu is not equal to 0

>   (mt3 <- median_test(y ~ x, data = ex, distribution = "exact",
+                       mid.score = "1")) # sign change!

	Exact 2-Sample Median Test

data:  y by x (no, yes)
Z = -0.2828, p-value = 1
alternative hypothesis: true mu is not equal to 0

> 
>   ### plot density and distribution of the standardized test statistics
>   layout(matrix(1:3, nrow = 3))
>   s1 <- support(mt1); d1 <- dperm(mt1, s1)
>   plot(s1, d1, type = "h", main = "Mid-score: 0",
+        xlab = "Test Statistic", ylab = "Density")
>   s2 <- support(mt2); d2 <- dperm(mt2, s2)
>   plot(s2, d2, type = "h", main = "Mid-score: 0.5",
+        xlab = "Test Statistic", ylab = "Density")
>   s3 <- support(mt3); d3 <- dperm(mt3, s3)
>   plot(s3, d3, type = "h", main = "Mid-score: 1",
+        xlab = "Test Statistic", ylab = "Density")
>   layout(1)
> 
> 
>   ### Length of YOY Gizzard Shad from Kokosing Lake, Ohio,
>   ### sampled in Summer 1984, Hollander & Wolfe (1999), Table 6.3, page 200
>   YOY <- data.frame(length = c(46, 28, 46, 37, 32, 41, 42, 45, 38, 44,
+                                42, 60, 32, 42, 45, 58, 27, 51, 42, 52,
+                                38, 33, 26, 25, 28, 28, 26, 27, 27, 27,
+                                31, 30, 27, 29, 30, 25, 25, 24, 27, 30),
+                     site = factor(c(rep("I", 10), rep("II", 10),
+                                     rep("III", 10), rep("IV", 10))))
> 
>   ### Kruskal-Wallis test, approximate exact p-value
>   kw <- kruskal_test(length ~ site, data = YOY,
+                      distribution = approximate(B = 9999))
>   kw

	Approximative Kruskal-Wallis Test

data:  length by site (I, II, III, IV)
chi-squared = 22.8524, p-value < 2.2e-16

>   pvalue(kw)
[1] 0
99 percent confidence interval:
 0.0000000000 0.0005297444 

> 
>   ### Nemenyi-Damico-Wolfe-Dunn test (joint ranking)
>   ### Hollander & Wolfe (1999), page 244
>   ### (where Steel-Dwass results are given)
>   NDWD <- oneway_test(length ~ site, data = YOY,
+       ytrafo = rank_trafo, xtrafo = mcp_trafo(site="Tukey"),
+       distribution = approximate(B = 90000))
> 
>   ### global p-value
>   print(pvalue(NDWD))
[1] 0.0004888889
99 percent confidence interval:
 0.0003199269 0.0007126921 

> 
>   ### sites (I = II) != (III = IV) at alpha = 0.01 (page 244)
>   print(pvalue(NDWD, method = "single-step"))
Warning in .local(object, ...) :
  multiple comparisons might be incorrect due to subset pivotality; use 'method = "npmcp"'
                     
II - I   0.9493555556
III - I  0.0092111111
IV - I   0.0074222222
III - II 0.0007000000
IV - II  0.0004888889
IV - III 0.9999333333
> 
> 
>   ### Jonckheere-Terpstra test for ordered groups
>   control <- c(40, 35, 38, 43, 44, 41)
>   rough <- c(38, 40, 47, 44, 40, 42)
>   accurate <- c(48, 40, 45, 43, 46, 44)
> 
>   pieces <- list(control, rough, accurate)
>   n <- c(6, 6, 6)
>   grp <- as.ordered(factor(rep(1:length(n), n)))
> 
>   (y <- unlist(pieces))
 [1] 40 35 38 43 44 41 38 40 47 44 40 42 48 40 45 43 46 44
>   k <- length(pieces)
>   (x <- as.ordered(factor(rep(1:k, n))))
 [1] 1 1 1 1 1 1 2 2 2 2 2 2 3 3 3 3 3 3
Levels: 1 < 2 < 3
> 
>   ## look at K. The second line just sums up.
>   ff <- function(x) {
+       K <- multcomp::contrMat(table(x), "Tukey")[, x]
+       as.vector(rep(1, nrow(K)) %*% K)
+   }
> 
>   it <- independence_test(y ~ x,
+       ytrafo = function(data) trafo(data, numeric_trafo = rank_trafo),
+       xtrafo = function(data) trafo(data, ordered_trafo = ff),
+       alternative = "greater")
>   it

	Asymptotic General Independence Test

data:  y by x (1 < 2 < 3)
Z = 2.0447, p-value = 0.02044
alternative hypothesis: greater

> 
> 
> 
> cleanEx()
> nameEx("MarginalHomogeneityTest")
> ### * MarginalHomogeneityTest
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: MarginalHomogeneityTest
> ### Title: Marginal Homogeneity Test
> ### Aliases: mh_test mh_test.formula mh_test.table mh_test.SymmetryProblem
> ### Keywords: htest
> 
> ### ** Examples
> 
>   ### Performance of prime minister
>   ### Agresti (2002, p. 409)
>   rating  <- c("Approve", "Disprove")
>   performance <- matrix(c(794, 150,
+                            86, 570),
+                         nrow = 2, byrow = TRUE,
+                         dimnames = list(First = rating,
+                                         Second = rating))
> 
>   ### Asymptotic McNemar Test
>   diag(performance) <- 0 # speed-up: only off-diagonal elements contribute
>   mh_test(as.table(performance))

	Asymptotic Marginal Homogeneity Test

data:  response by
	 conditions (First, Second) 
	 stratified by block
chi-squared = 17.3559, df = 1, p-value = 3.099e-05

> 
>   ### Exact McNemar Test
>   mh_test(as.table(performance), distribution = "exact")

	Exact Marginal Homogeneity Test

data:  response by
	 conditions (First, Second) 
	 stratified by block
chi-squared = 17.3559, p-value = 3.716e-05

> 
> 
>   ### Opinions on Pre- and Extramarital Sex, Agresti (2002), page 421
>   opinions <- c("always wrong", "almost always wrong",
+                 "wrong only sometimes", "not wrong at all")
>   PreExSex <- as.table(matrix(c(144, 33, 84, 126,
+                                   2,  4, 14,  29,
+                                   0,  2,  6,  25,
+                                   0,  0,  1,  5), nrow = 4,
+                               dimnames = list(PremaritalSex = opinions,
+                                               ExtramaritalSex = opinions)))
> 
>   ### treating response as nominal
>   mh_test(PreExSex)

	Asymptotic Marginal Homogeneity Test

data:  response by
	 conditions (ExtramaritalSex, PremaritalSex) 
	 stratified by block
chi-squared = 271.9222, df = 3, p-value < 2.2e-16

> 
>   ### and as ordinal
>   mh_test(PreExSex, scores = list(response = 1:length(opinions)))

	Asymptotic Marginal Homogeneity Test for Ordered Data

data:  response (ordered) by
	 conditions (ExtramaritalSex, PremaritalSex) 
	 stratified by block
Z = -16.4542, p-value < 2.2e-16
alternative hypothesis: two.sided

> ## Don't show: ## Not run: 
> ##D   ### example taken from
> ##D   ### http://www.john-uebersax.com/stat/mcnemar.htm#stuart
> ##D   rating <- c("low", "moderate", "high")
> ##D   x <- as.table(matrix(c(20, 10,  5,
> ##D                          3, 30, 15,
> ##D                          0,  5, 40),
> ##D                        ncol = 3, byrow = TRUE,
> ##D                        dimnames = list(Rater1 = rating, Rater2 = rating)))
> ##D   ### test statistic W_0 = 13.76
> ##D   mh_test(x)
> ## End(Not run)## End Don't show
> 
>   ### Vote intention example from Madansky (1963, p. 107--108)
>   intention <- c("Republican","Democratic","Uncertain")
>   vote <- as.table(array(c(120, 1,  8, 2,   2,  1, 2, 1,  7,
+                              6, 2,  1, 1, 103,  5, 1, 4,  8,
+                             20, 3, 31, 1,   6, 30, 2, 1, 81),
+                          dim = c(3, 3, 3),
+                          dimnames = list(July = intention,
+                                          August = intention,
+                                          June = intention)))
>   ### test statistic Q = 70.77
>   mh_test(vote)

	Asymptotic Marginal Homogeneity Test

data:  response by
	 conditions (August, July, June) 
	 stratified by block
chi-squared = 70.763, df = 4, p-value = 1.565e-14

> 
> 
>   ### Cross-over study
>   ### http://www.nesug.org/proceedings/nesug00/st/st9005.pdf
>   relief <- c("none", "moderate", "complete")
>   dysmenorrhea <- as.table(array(c(6, 2, 1,  4, 3, 0,  5, 2, 2,
+                                    3, 1, 0, 13, 3, 0, 10, 1, 0,
+                                    1, 2, 1,  8, 1, 1, 14, 2, 0),
+                                  dim = c(3, 3, 3),
+                                  dimnames =  list("Placebo" = relief,
+                                                   "High dose" = relief,
+                                                   "Low dose" = relief)))
> 
>   ### Ordered response, Q = 53.76
>   mh_test(dysmenorrhea, scores = list(response = 1:3))

	Asymptotic Marginal Homogeneity Test for Ordered Data

data:  response (ordered) by
	 conditions (High.dose, Low.dose, Placebo) 
	 stratified by block
chi-squared = 53.7617, df = 2, p-value = 2.117e-12

> 
>   ### Both response and measurement conditions ordered, Q = 47.29
>   mh_test(dysmenorrhea, scores = list(response = 1:3, conditions = 3:1))

	Asymptotic Marginal Homogeneity Test for Ordered Data

data:  response (ordered) by
	 conditions (High.dose < Low.dose < Placebo) 
	 stratified by block
Z = 6.8764, p-value = 6.138e-12
alternative hypothesis: two.sided

> 
> 
> 
> 
> cleanEx()
> nameEx("MaxstatTest")
> ### * MaxstatTest
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: MaxstatTest
> ### Title: Maximally Selected Statistics
> ### Aliases: maxstat_test maxstat_test.formula maxstat_test.table
> ###   maxstat_test.IndependenceProblem
> ### Keywords: htest
> 
> ### ** Examples
> 
>   ## Don't show: 
> options(useFancyQuotes = FALSE)
> ## End Don't show
>   ### analysis of the tree pipit data in Mueller and Hothorn (2004)
>   maxstat_test(counts ~ coverstorey, data = treepipit)

	Asymptotic Generalized Maximally Selected Statistics

data:  counts by coverstorey
maxT = 4.3139, p-value = 0.0001796
alternative hypothesis: two.sided
sample estimates:
  "best" cutpoint: <= 40

> 
>   ### and for all possible covariates (simultaneously)
>   mt <- maxstat_test(counts ~ ., data = treepipit)
>   mt@estimates$estimate
  "best" cutpoint: <= 280
       covariable: fdist
> 
> 
>   ### reproduce applications in Sections 7.2 and 7.3
>   ### of Hothorn & Lausen (2003) with limiting distribution
>   maxstat_test(Surv(time, event) ~  EF, data = hohnloser,
+                ytrafo = function(data)
+                    trafo(data, surv_trafo = function(y)
+                        logrank_trafo(y, ties.method = "Hothorn-Lausen")))

	Asymptotic Generalized Maximally Selected Statistics

data:  Surv(time, event) by EF
maxT = 3.5691, p-value = 0.004286
alternative hypothesis: two.sided
sample estimates:
  "best" cutpoint: <= 39

> 
>   data("sphase", package = "TH.data")
>   maxstat_test(Surv(RFS, event) ~  SPF, data = sphase,
+                ytrafo = function(data)
+                    trafo(data, surv_trafo = function(y)
+                        logrank_trafo(y, ties.method = "Hothorn-Lausen")))

	Asymptotic Generalized Maximally Selected Statistics

data:  Surv(RFS, event) by SPF
maxT = 2.4033, p-value = 0.1555
alternative hypothesis: two.sided
sample estimates:
  "best" cutpoint: <= 107

> 
> 
>   ### analysis of the jobsatisfaction data
>   maxstat_test(jobsatisfaction)

	Asymptotic Generalized Maximally Selected Statistics

data:  Job.Satisfaction by
	 Income (<5000, 5000-15000, 15000-25000, >25000) 
	 stratified by Gender
maxT = 2.3349, p-value = 0.2993
alternative hypothesis: two.sided
sample estimates:
  "best" cutpoint: {<5000, 5000-15000} vs. {15000-25000, >25000}

> 
>   ### and treating both Income and Job.Satisfaction as ordered factors
>   maxstat_test(jobsatisfaction, scores = list(Job.Satisfaction = 1:4,
+                                               Income = 1:4))

	Asymptotic Generalized Maximally Selected Statistics

data:  Job.Satisfaction (ordered) by
	 Income (<5000 < 5000-15000 < 15000-25000 < >25000) 
	 stratified by Gender
maxT = 2.9983, p-value = 0.007662
alternative hypothesis: two.sided
sample estimates:
  "best" cutpoint: {<5000, 5000-15000} vs. {15000-25000, >25000}

> 
> 
> 
> cleanEx()
> nameEx("PermutationDistribution-methods")
> ### * PermutationDistribution-methods
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: PermutationDistribution-methods
> ### Title: The Permutation Distribution
> ### Aliases: dperm dperm-methods dperm,AsymptNullDistribution-method
> ###   dperm,IndependenceTest-method dperm,NullDistribution-method pperm
> ###   pperm-methods pperm,AsymptNullDistribution-method
> ###   pperm,IndependenceTest-method pperm,NullDistribution-method qperm
> ###   qperm-methods qperm,AsymptNullDistribution-method
> ###   qperm,IndependenceTest-method qperm,NullDistribution-method rperm
> ###   rperm-methods rperm,IndependenceTest-method
> ###   rperm,NullDistribution-method support support-methods
> ###   support,IndependenceTest-method support,NullDistribution-method
> ### Keywords: methods htest distribution
> 
> ### ** Examples
> 
> ## Two-sample problem
> dta <- data.frame(
+     y = rnorm(20),
+     x = gl(2, 10)
+ )
> 
> ## Ansari-Bradley test
> at <- ansari_test(y ~ x, data = dta, distribution = "exact")
> 
> ## Support of the exact distribution of the Ansari-Bradley statistic
> supp <- support(at)
> 
> ## Density of the exact distribution of the Ansari-Bradley statistic
> dens <- dperm(at, supp)
> 
> ## Plotting the density
> plot(supp, dens, type = "s")
> 
> ## 95 % quantile
> qperm(at, 0.95)
[1] 1.669331
> 
> ## One-sided p-value
> pperm(at, statistic(at))
       1 
0.698635 
> 
> ## Random number generation
> rperm(at, 5)
[1] 0.9105443 0.4552721 0.7587869 0.1517574 0.1517574
> 
> 
> 
> cleanEx()
> nameEx("ScaleTests")
> ### * ScaleTests
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: ScaleTests
> ### Title: Independent Two- and K-Sample Scale Tests
> ### Aliases: taha_test taha_test.formula taha_test.IndependenceProblem
> ###   klotz_test klotz_test.formula klotz_test.IndependenceProblem
> ###   mood_test mood_test.formula mood_test.IndependenceProblem ansari_test
> ###   ansari_test.formula ansari_test.IndependenceProblem fligner_test
> ###   fligner_test.formula fligner_test.IndependenceProblem conover_test
> ###   conover_test.formula conover_test.IndependenceProblem
> ### Keywords: htest
> 
> ### ** Examples
> 
> 
>   ### Serum Iron Determination Using Hyland Control Sera
>   ### Hollander & Wolfe (1999), page 147
>   sid <- data.frame(
+       serum = c(111, 107, 100, 99, 102, 106, 109, 108, 104, 99,
+                 101, 96, 97, 102, 107, 113, 116, 113, 110, 98,
+                 107, 108, 106, 98, 105, 103, 110, 105, 104,
+                 100, 96, 108, 103, 104, 114, 114, 113, 108, 106, 99),
+       method = factor(gl(2, 20), labels = c("Ramsay", "Jung-Parekh")))
> 
>   ### Ansari-Bradley test, asymptotical p-value
>   ansari_test(serum ~ method, data = sid)

	Asymptotic 2-Sample Ansari-Bradley Test

data:  serum by method (Ramsay, Jung-Parekh)
Z = -1.3363, p-value = 0.1815
alternative hypothesis: true ratio of scales is not equal to 1

> 
>   ### exact p-value
>   ansari_test(serum ~ method, data = sid, distribution = "exact")

	Exact 2-Sample Ansari-Bradley Test

data:  serum by method (Ramsay, Jung-Parekh)
Z = -1.3363, p-value = 0.1881
alternative hypothesis: true ratio of scales is not equal to 1

> 
> 
>   ### Platelet Counts of Newborn Infants
>   ### Hollander & Wolfe (1999), Table 5.4, page 171
>   platalet_counts <- data.frame(
+       counts = c(120, 124, 215, 90, 67, 95, 190, 180, 135, 399,
+                  12, 20, 112, 32, 60, 40),
+       treatment = factor(c(rep("Prednisone", 10), rep("Control", 6))))
> 
>   ### Lepage test, Hollander & Wolfe (1999), page 172
>   lt <- independence_test(counts ~ treatment, data = platalet_counts,
+       ytrafo = function(data) trafo(data, numeric_trafo = function(x)
+           cbind(rank_trafo(x), ansari_trafo(x))),
+       teststat = "quadratic", distribution = approximate(B = 9999))
>   lt

	Approximative General Independence Test

data:  counts by treatment (Control, Prednisone)
chi-squared = 9.3384, p-value = 0.0042

> 
>   ### where did the rejection come from? Use maximum statistic
>   ### instead of a quadratic form
>   ltmax <- independence_test(counts ~ treatment, data = platalet_counts,
+       ytrafo = function(data) trafo(data, numeric_trafo = function(x)
+           matrix(c(rank_trafo(x), ansari_trafo(x)), ncol = 2,
+                  dimnames = list(1:length(x), c("Location", "Scale")))))
> 
>   ### single-step adjustment points to a difference in location
>   pvalue(ltmax, method = "single-step")
         Location     Scale
Control 0.0067991 0.6189816
> 
>   ### step-down is slightly more powerful
>   pvalue(ltmax, method = "step-down")
         Location     Scale
Control 0.0067991 0.3827331
> 
>   ### The same results are obtained from simple Sidak or Sidak-Holm procedures,
>   ### respectively, since the correlation between the Wilcoxon and
>   ### Ansari-Bradley test statistics is zero
>   cov2cor(covariance(ltmax))
                 Control:Location Control:Scale
Control:Location                1             0
Control:Scale                   0             1
>   pvalue(ltmax, method = "single-step", distribution = "marginal", type = "Sidak")
         Location     Scale
Control 0.0067991 0.6189816
>   pvalue(ltmax, method = "step-down", distribution = "marginal", type = "Sidak")
         Location     Scale
Control 0.0067991 0.3827331
> 
> 
> 
> cleanEx()
> nameEx("SurvTest")
> ### * SurvTest
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: SurvTest
> ### Title: Independent Two- and K-Sample Tests for Censored Data
> ### Aliases: surv_test surv_test.formula surv_test.IndependenceProblem
> ### Keywords: htest
> 
> ### ** Examples
> 
> 
>   ### asymptotic tests for carcinoma data
>   surv_test(Surv(time, event) ~ stadium, data = ocarcinoma)

	Asymptotic 2-Sample Logrank Test

data:  Surv(time, event) by stadium (II, IIA)
Z = 2.3373, p-value = 0.01942
alternative hypothesis: true theta is not equal to 1

>   survdiff(Surv(time, event) ~ stadium, data = ocarcinoma)
Call:
survdiff(formula = Surv(time, event) ~ stadium, data = ocarcinoma)

             N Observed Expected (O-E)^2/E (O-E)^2/V
stadium=II  15        6     11.3      2.51      5.57
stadium=IIA 20       16     10.7      2.67      5.57

 Chisq= 5.6  on 1 degrees of freedom, p= 0.0183 
> 
> 
>   ### example data given in Callaert (2003)
>   exdata <- data.frame(time = c(1, 1, 5, 6, 6, 6, 6, 2, 2, 2, 3, 4, 4, 5, 5),
+                        group = factor(c(rep(0, 7), rep(1, 8))))
>   ### p = 0.0523
>   survdiff(Surv(time) ~ group, data = exdata)
Call:
survdiff(formula = Surv(time) ~ group, data = exdata)

        N Observed Expected (O-E)^2/E (O-E)^2/V
group=0 7        7     9.84      0.82      3.76
group=1 8        8     5.16      1.56      3.76

 Chisq= 3.8  on 1 degrees of freedom, p= 0.0523 
>   ### p = 0.0505
>   surv_test(Surv(time) ~ group, data = exdata, distribution = "exact")

	Exact 2-Sample Logrank Test

data:  Surv(time) by group (0, 1)
Z = 1.9201, p-value = 0.05051
alternative hypothesis: true theta is not equal to 1

>   ### p = 0.0468
>   surv_test(Surv(time) ~ group, data = exdata, distribution = "exact",
+             ties.method = "average-scores")

	Exact 2-Sample Logrank Test

data:  Surv(time) by group (0, 1)
Z = 1.9865, p-value = 0.04678
alternative hypothesis: true theta is not equal to 1

> 
> 
>   ### lung cancer example from StatXact
>   lungcancer <-
+       data.frame(time = c(257, 476, 355, 1779, 355,
+                           191, 563, 242, 285, 16, 16, 16, 257, 16),
+                  event = c(0, 0, 1, 1, 0,
+                            1, 1, 1, 1, 1, 1, 1, 1, 1),
+                  group = factor(rep(1:2, c(5, 9)),
+                                 labels = c("newdrug", "control")))
> 
>   ### StatXact 9 manual, page 214
>   with(lungcancer,
+        logrank_trafo(Surv(time, event), ties.method = "average-scores"))
 [1]  0.65870518  1.02537185  0.02537185  1.52537185  1.02537185 -0.57740593
 [7]  0.52537185 -0.46629482 -0.17462815 -0.80648518 -0.80648518 -0.80648518
[13] -0.34129482 -0.80648518
> 
>   ### StatXact 9 manual, page 215
>   surv_test(Surv(time, event) ~ group, data = lungcancer,
+             distribution = "exact", ties.method = "average-scores")

	Exact 2-Sample Logrank Test

data:  Surv(time, event) by group (newdrug, control)
Z = 2.9492, p-value = 0.000999
alternative hypothesis: true theta is not equal to 1

> 
>   ### StatXact 9 manual, page 222
>   surv_test(Surv(time, event) ~ group, data = lungcancer,
+             distribution = "exact", ties.method = "average-scores",
+             type = "Prentice")

	Exact 2-Sample Prentice Test

data:  Surv(time, event) by group (newdrug, control)
Z = 2.7813, p-value = 0.002997
alternative hypothesis: true theta is not equal to 1

> 
> 
>   ### versatile test (Lee, 1996) using a range of rho and gamma
>   rho.gamma <- expand.grid(rho = seq(-2, 2, 1), gamma = seq(0, 2, 1))
>   vt <- independence_test(Surv(time, event) ~ group, data = lungcancer,
+                           distribution = approximate(B = 10000),
+                           ytrafo = function(data)
+                               trafo(data, surv_trafo = function(y)
+                                   logrank_trafo(y,
+                                                 ties.method = "average-scores",
+                                                 type = "Fleming-Harrington",
+                                                 rho = rho.gamma["rho"],
+                                                 gamma = rho.gamma["gamma"])))
>   pvalue(vt, method = "step-down")
        rho = -2, gamma = 0 rho = -1, gamma = 0 rho = 0, gamma = 0
newdrug              0.0111              0.0038             0.0028
        rho = 1, gamma = 0 rho = 2, gamma = 0 rho = -2, gamma = 1
newdrug             0.0052             0.0111               0.038
        rho = -1, gamma = 1 rho = 0, gamma = 1 rho = 1, gamma = 1
newdrug              0.0125             0.0103             0.0028
        rho = 2, gamma = 1 rho = -2, gamma = 2 rho = -1, gamma = 2
newdrug             0.0028              0.0823              0.0467
        rho = 0, gamma = 2 rho = 1, gamma = 2 rho = 2, gamma = 2
newdrug             0.0191             0.0111             0.0063
> 
> 
> 
> 
> cleanEx()
> nameEx("SymmetryTests")
> ### * SymmetryTests
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: SymmetryTests
> ### Title: Symmetry Tests
> ### Aliases: quade_test quade_test.formula quade_test.SymmetryProblem
> ###   friedman_test friedman_test.formula friedman_test.SymmetryProblem
> ###   wilcoxsign_test wilcoxsign_test.formula
> ###   wilcoxsign_test.SymmetryProblem sign_test sign_test.formula
> ###   sign_test.SymmetryProblem
> ### Keywords: htest
> 
> ### ** Examples
> 
>   ### Data from Quade (1979, p. 683)
>   dta <- data.frame(
+       y = c(52, 45, 38,
+             63, 79, 50,
+             45, 57, 39,
+             53, 51, 43,
+             47, 50, 56,
+             62, 72, 49,
+             49, 52, 40),
+        x = factor(rep(LETTERS[1:3], 7)),
+        b = factor(rep(1:7, each = 3)))
> 
>   ### Approximate (Monte Carlo) Friedman test
>   friedman_test(y ~ x | b, data = dta,
+                 distribution = approximate(B = 10000))

	Approximative Friedman Test

data:  y by x (A, B, C) 
	 stratified by b
chi-squared = 6, p-value = 0.0521

> 
>   ### Approximate (Monte Carlo) Quade test
>   ### Quade (1979, p.683), W = 8.157
>   (qt <- quade_test(y ~ x | b, data = dta,
+                     distribution = approximate(B = 10000)))

	Approximative Quade Test

data:  y by x (A, B, C) 
	 stratified by b
chi-squared = 8.1571, p-value = 0.0059

> 
>   ### Comparison with R's quade.test() function
>   quade.test(y ~ x | b, data = dta)

	Quade test

data:  y and x and b
Quade F = 8.3765, num df = 2, denom df = 12, p-value = 0.005284

> 
>   ### quade.test() uses an F-statistic
>   b <- nlevels(qt@statistic@block)
>   A <- sum(qt@statistic@y^2)
>   B <- sum(statistic(qt, "linear")^2) / b
>   (b - 1) * B / (A - B) # F = 8.3765
[1] 8.376528
> 
> 
>   ### Hollander & Wolfe (1999), Table 7.1, page 274
>   ### Comparison of three methods ("round out", "narrow angle", and
>   ###  "wide angle") for rounding first base.
>   RoundingTimes <- data.frame(
+       times = c(5.40, 5.50, 5.55,
+                 5.85, 5.70, 5.75,
+                 5.20, 5.60, 5.50,
+                 5.55, 5.50, 5.40,
+                 5.90, 5.85, 5.70,
+                 5.45, 5.55, 5.60,
+                 5.40, 5.40, 5.35,
+                 5.45, 5.50, 5.35,
+                 5.25, 5.15, 5.00,
+                 5.85, 5.80, 5.70,
+                 5.25, 5.20, 5.10,
+                 5.65, 5.55, 5.45,
+                 5.60, 5.35, 5.45,
+                 5.05, 5.00, 4.95,
+                 5.50, 5.50, 5.40,
+                 5.45, 5.55, 5.50,
+                 5.55, 5.55, 5.35,
+                 5.45, 5.50, 5.55,
+                 5.50, 5.45, 5.25,
+                 5.65, 5.60, 5.40,
+                 5.70, 5.65, 5.55,
+                 6.30, 6.30, 6.25),
+       methods = factor(rep(c("Round Out", "Narrow Angle", "Wide Angle"), 22)),
+       block = factor(rep(1:22, rep(3, 22))))
> 
>   ### classical global test
>   friedman_test(times ~ methods | block, data = RoundingTimes)

	Asymptotic Friedman Test

data:  times by
	 methods (Narrow Angle, Round Out, Wide Angle) 
	 stratified by block
chi-squared = 11.1429, df = 2, p-value = 0.003805

> 
>   ### parallel coordinates plot
>   matplot(t(matrix(RoundingTimes$times, ncol = 3, byrow = TRUE)),
+           type = "l", col = 1, lty = 1, axes = FALSE, ylab = "Time",
+           xlim = c(0.5, 3.5))
>   axis(1, at = 1:3, labels = c("Round Out", "Narrow Angle", "Wide Angle"))
>   axis(2)
> 
>   ### where do the differences come from?
>   ### Wilcoxon-Nemenyi-McDonald-Thompson test
>   ### Hollander & Wolfe (1999), page 295
>   ### all pairwise comparisons
>   rtt <- symmetry_test(times ~ methods | block, data = RoundingTimes,
+        xtrafo = mcp_trafo(methods = "Tukey"),
+        ytrafo = function(data)
+            trafo(data, numeric_trafo = rank_trafo, block = RoundingTimes$block)
+        )
> 
>   ### a global test, again
>   print(pvalue(rtt))
[1] 0.003466348
99 percent confidence interval:
 0.003169085 0.003763611 

> 
>   ### simultaneous P-values for all pair comparisons
>   ### Wide Angle vs. Round Out differ (Hollander and Wolfe, 1999, page 296)
>   print(pvalue(rtt, method = "single-step"))
Warning in .local(object, ...) :
  multiple comparisons might be incorrect due to subset pivotality; use 'method = "npmcp"'
                                     
Round Out - Narrow Angle  0.623914237
Wide Angle - Narrow Angle 0.053979240
Wide Angle - Round Out    0.003389065
> 
> 
>   ### Strength Index of Cotton, Hollander & Wolfe (1999), Table 7.5, page 286
>   sc <- data.frame(block = factor(c(rep(1, 5), rep(2, 5), rep(3, 5))),
+                    potash = ordered(rep(c(144, 108, 72, 54, 36), 3),
+                                     levels = c(144, 108, 72, 54, 36)),
+                    strength = c(7.46, 7.17, 7.76, 8.14, 7.63,
+                                 7.68, 7.57, 7.73, 8.15, 8.00,
+                                 7.21, 7.80, 7.74, 7.87, 7.93))
> 
>   ### Page test for ordered alternatives
>   friedman_test(strength ~ potash | block, data = sc)

	Asymptotic Page Test

data:  strength by
	 potash (144 < 108 < 72 < 54 < 36) 
	 stratified by block
Z = 2.6558, p-value = 0.007912
alternative hypothesis: two.sided

> 
>   ### one-sided p-value
>   pvalue(friedman_test(strength ~ potash | block, data = sc,
+                        alternative = "greater"))
            
0.003955894 
> 
>   ### approximate null distribution via Monte Carlo
>   pvalue(friedman_test(strength ~ potash | block, data = sc,
+                        distribution = approximate(B = 9999)))
[1] 0.00480048
99 percent confidence interval:
 0.003205889 0.006883641 

> 
> 
>   ### example from ?wilcox.test
>   y1 <- c(1.83,  0.50,  1.62,  2.48, 1.68, 1.88, 1.55, 3.06, 1.30)
>   y2 <- c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29)
> 
>   wilcox.test(y1, y2, paired = TRUE, alternative = "greater")

	Wilcoxon signed rank test

data:  y1 and y2
V = 40, p-value = 0.01953
alternative hypothesis: true location shift is greater than 0

>   (wt <- wilcoxsign_test(y1 ~ y2, alternative = "greater",
+                          distribution = "exact"))

	Exact Wilcoxon-Pratt Signed-Rank Test

data:  y by x (pos, neg) 
	 stratified by block
Z = 2.0732, p-value = 0.01953
alternative hypothesis: true mu is greater than 0

>   statistic(wt, "linear") # same as wilcox.test
      
pos 40
>   midpvalue(wt) # mid-p-value
[1] 0.01660156
> 
>   (st <- sign_test(y1 ~ y2, alternative = "greater",
+                    distribution = "exact"))

	Exact Sign Test

data:  y by x (pos, neg) 
	 stratified by block
Z = 1.6667, p-value = 0.08984
alternative hypothesis: true mu is greater than 0

>   midpvalue(st) # mid-p-value
[1] 0.0546875
> 
>   ### with explicit group and block information
>   dta <- data.frame(y = c(y1, y2), x = gl(2, length(y1)),
+                     block = factor(rep(seq_along(y1), 2)))
> 
>   wilcoxsign_test(y ~ x | block, data = dta,
+                   alternative = "greater", distribution = "exact")

	Exact Wilcoxon-Pratt Signed-Rank Test

data:  y by x (pos, neg) 
	 stratified by block
Z = 2.0732, p-value = 0.01953
alternative hypothesis: true mu is greater than 0

> 
>   sign_test(y ~ x | block, data = dta,
+             alternative = "greater", distribution = "exact")

	Exact Sign Test

data:  y by x (pos, neg) 
	 stratified by block
Z = 1.6667, p-value = 0.08984
alternative hypothesis: true mu is greater than 0

> 
>   ### for two samples, the Quade test is equivalent to the signed-rank test
>   quade_test(y ~ x | block, data = dta, distribution = "exact")

	Exact Quade Test

data:  y by x (1, 2) 
	 stratified by block
chi-squared = 4.2982, p-value = 0.03906

> 
>   wilcoxsign_test(y ~ x | block, data = dta, distribution = "exact")

	Exact Wilcoxon-Pratt Signed-Rank Test

data:  y by x (pos, neg) 
	 stratified by block
Z = 2.0732, p-value = 0.03906
alternative hypothesis: true mu is not equal to 0

> 
>   ### for two samples, the Friedman test is equivalent to the sign test
>   friedman_test(y ~ x | block, data = dta, distribution = "exact")

	Exact Friedman Test

data:  y by x (1, 2) 
	 stratified by block
chi-squared = 2.7778, p-value = 0.1797

> 
>   sign_test(y ~ x | block, data = dta, distribution = "exact")

	Exact Sign Test

data:  y by x (pos, neg) 
	 stratified by block
Z = 1.6667, p-value = 0.1797
alternative hypothesis: true mu is not equal to 0

> 
> 
> 
> cleanEx()
> nameEx("Transformations")
> ### * Transformations
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Transformations
> ### Title: Functions for Data Transformations
> ### Aliases: trafo id_trafo rank_trafo normal_trafo median_trafo
> ###   savage_trafo consal_trafo koziol_trafo klotz_trafo mood_trafo
> ###   ansari_trafo fligner_trafo logrank_trafo logrank_weight maxstat_trafo
> ###   fmaxstat_trafo ofmaxstat_trafo f_trafo of_trafo mcp_trafo
> ### Keywords: manip
> 
> ### ** Examples
> 
> 
>   ### dummy matrices, 2-sample problem (only one column)
>   f_trafo(y <- gl(2, 5))
   1
1  1
2  1
3  1
4  1
5  1
6  0
7  0
8  0
9  0
10 0
> 
>   ### score matrices
>   of_trafo(y <- ordered(gl(3, 5)))
      [,1]
 [1,]    1
 [2,]    1
 [3,]    1
 [4,]    1
 [5,]    1
 [6,]    2
 [7,]    2
 [8,]    2
 [9,]    2
[10,]    2
[11,]    3
[12,]    3
[13,]    3
[14,]    3
[15,]    3
> 
>   ### K-sample problem (K columns)
>   f_trafo(y <- gl(5, 2))
   1 2 3 4 5
1  1 0 0 0 0
2  1 0 0 0 0
3  0 1 0 0 0
4  0 1 0 0 0
5  0 0 1 0 0
6  0 0 1 0 0
7  0 0 0 1 0
8  0 0 0 1 0
9  0 0 0 0 1
10 0 0 0 0 1
attr(,"assign")
[1] 1 1 1 1 1
attr(,"contrasts")
attr(,"contrasts")$x
[1] "contr.treatment"

> 
>   ### normal scores
>   normal_trafo(x <- rnorm(10))
 [1] -0.6045853 -0.1141853 -1.3351777  1.3351777  0.1141853 -0.9084579
 [7]  0.3487557  0.9084579  0.6045853 -0.3487557
> 
>   ### and now together
>   trafo(data.frame(x = x, y = y), numeric_trafo = normal_trafo)
            x y.1 y.2 y.3 y.4 y.5
1  -0.6045853   1   0   0   0   0
2  -0.1141853   1   0   0   0   0
3  -1.3351777   0   1   0   0   0
4   1.3351777   0   1   0   0   0
5   0.1141853   0   0   1   0   0
6  -0.9084579   0   0   1   0   0
7   0.3487557   0   0   0   1   0
8   0.9084579   0   0   0   1   0
9   0.6045853   0   0   0   0   1
10 -0.3487557   0   0   0   0   1
attr(,"assign")
[1] 1 2 2 2 2 2
> 
>   ### the same, more flexible when multiple variables are in play
>   trafo(data.frame(x = x, y = y), var_trafo = list(x = normal_trafo))
            x y.1 y.2 y.3 y.4 y.5
1  -0.6045853   1   0   0   0   0
2  -0.1141853   1   0   0   0   0
3  -1.3351777   0   1   0   0   0
4   1.3351777   0   1   0   0   0
5   0.1141853   0   0   1   0   0
6  -0.9084579   0   0   1   0   0
7   0.3487557   0   0   0   1   0
8   0.9084579   0   0   0   1   0
9   0.6045853   0   0   0   0   1
10 -0.3487557   0   0   0   0   1
attr(,"assign")
[1] 1 2 2 2 2 2
> 
>   ### maximally selected statistics
>   maxstat_trafo(rnorm(10))
   x <= -2.215 x <= -0.621 x <= -0.045 x <= -0.016 x <= 0.39 x <= 0.594
1            0           0           0           0         0          0
2            0           0           0           0         1          1
3            0           1           1           1         1          1
4            1           1           1           1         1          1
5            0           0           0           0         0          0
6            0           0           1           1         1          1
7            0           0           0           1         1          1
8            0           0           0           0         0          0
9            0           0           0           0         0          0
10           0           0           0           0         0          1
   x <= 0.821 x <= 0.944 x <= 1.125
1           0          0          0
2           1          1          1
3           1          1          1
4           1          1          1
5           0          0          1
6           1          1          1
7           1          1          1
8           0          1          1
9           1          1          1
10          1          1          1
> 
>   ### apply transformation blockwise (e.g. for Friedman test)
>   trafo(data.frame(y = 1:20), numeric_trafo = rank_trafo, block = gl(4, 5))
       
 [1,] 1
 [2,] 2
 [3,] 3
 [4,] 4
 [5,] 5
 [6,] 1
 [7,] 2
 [8,] 3
 [9,] 4
[10,] 5
[11,] 1
[12,] 2
[13,] 3
[14,] 4
[15,] 5
[16,] 1
[17,] 2
[18,] 3
[19,] 4
[20,] 5
attr(,"assign")
[1] 1
> 
>   ### multiple comparisons
>   mcp_trafo(x = "Tukey")(data.frame(x = gl(3, 3)))
  2 - 1 3 - 1 3 - 2
1    -1    -1     0
2    -1    -1     0
3    -1    -1     0
4     1     0    -1
5     1     0    -1
6     1     0    -1
7     0     1     1
8     0     1     1
9     0     1     1
attr(,"assign")
[1] 1 1 1
attr(,"contrast")

	 Multiple Comparisons of Means: Tukey Contrasts

       1  2 3
2 - 1 -1  1 0
3 - 1 -1  0 1
3 - 2  0 -1 1
> 
> 
> 
> 
> cleanEx()
> nameEx("alpha")
> ### * alpha
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: alpha
> ### Title: Genetic Components of Alcoholism
> ### Aliases: alpha
> ### Keywords: datasets
> 
> ### ** Examples
> 
> 
>   boxplot(elevel ~ alength, data = alpha)
>   kruskal_test(elevel ~ alength, data = alpha)

	Asymptotic Kruskal-Wallis Test

data:  elevel by alength (short, intermediate, long)
chi-squared = 8.8302, df = 2, p-value = 0.01209

> 
> 
> 
> 
> cleanEx()
> nameEx("alzheimer")
> ### * alzheimer
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: alzheimer
> ### Title: Smoking and Alzheimer's Disease
> ### Aliases: alzheimer
> ### Keywords: datasets
> 
> ### ** Examples
> 
> 
>   ### spineplots
>   layout(matrix(1:2, ncol = 2))
>   spineplot(disease ~ smoking, data = alzheimer, subset = gender == "Male",
+             main = "Male")
>   spineplot(disease ~ smoking, data = alzheimer, subset = gender == "Female",
+             main = "Female")
> 
>   ### Cochran-Mantel-Haenszel test
>   cmh_test(disease ~ smoking | gender, data = alzheimer)

	Asymptotic Generalized Cochran-Mantel-Haenszel Test

data:  disease by
	 smoking (None, <10, 10-20, >20) 
	 stratified by gender
chi-squared = 23.3163, df = 6, p-value = 0.0006972

> 
> 
> 
> 
> cleanEx()
> nameEx("asat")
> ### * asat
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: asat
> ### Title: Toxicological Study on Female Wistar Rats
> ### Aliases: asat
> ### Keywords: datasets
> 
> ### ** Examples
> 
> 
>   ### proof-of-safety based on ratio of medians
>   pos <- wilcox_test(I(log(asat)) ~ group, data = asat, alternative = "less", 
+                      conf.int = TRUE, distribution = "exact")
> 
>   ### one-sided confidence set. Safety cannot be concluded since the effect of
>   ### the compound exceeds 20% of the control median
>   exp(confint(pos)$conf.int)
[1] 0.000000 1.337778
attr(,"conf.level")
[1] 0.95
> 
> 
> 
> 
> cleanEx()
> nameEx("coin")
> ### * coin
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: coin
> ### Title: General Information on the coin Package
> ### Aliases: coin
> ### Keywords: misc
> 
> ### ** Examples
> 
> 
>     ### if you are interested in the internals:
>     ### generate doxygen documentation
>     ## Not run: 
> ##D 
> ##D         ### download src package into temp dir
> ##D         tmpdir <- tempdir()
> ##D         tgz <- download.packages("coin", destdir = tmpdir, type = "source")[2]
> ##D         ### extract
> ##D         untar(tgz, exdir = tmpdir)
> ##D         wd <- setwd(file.path(tmpdir, "coin"))
> ##D         ### run doxygen (assuming it is there)
> ##D         system("doxygen inst/doxygen.cfg")
> ##D         setwd(wd)
> ##D         ### have fun
> ##D         browseURL(file.path(tmpdir, "coin", "inst",
> ##D                             "documentation", "html", "index.html"))
> ##D     
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("expectation-methods")
> ### * expectation-methods
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: expectation-methods
> ### Title: Computing the Expectation, Variance and Covariance of the Linear
> ###   Statistic
> ### Aliases: expectation expectation-methods
> ###   expectation,IndependenceLinearStatistic-method
> ###   expectation,IndependenceTest-method variance variance-methods
> ###   variance,CovarianceMatrix-method
> ###   variance,IndependenceLinearStatistic-method
> ###   variance,IndependenceTest-method variance,Variance-method covariance
> ###   covariance-methods covariance,CovarianceMatrix-method
> ###   covariance,IndependenceLinearStatistic-method
> ###   covariance,IndependenceTest-method
> ### Keywords: methods
> 
> ### ** Examples
> 
> dta <- data.frame(
+     y = gl(3, 2),
+     x = sample(gl(3, 2))
+ )
> 
> ## Cochran-Mantel-Haenszel Test
> ct <- cmh_test(y ~ x, data = dta)
> 
> ## The linear statistic, i.e., the contingency table...
> (l <- statistic(ct, type = "linear"))
  1 2 3
1 1 0 1
2 0 2 0
3 1 0 1
> 
> ## ...and its expectation...
> (El <- expectation(ct))
      1:1       2:1       3:1       1:2       2:2       3:2       1:3       2:3 
0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 
      3:3 
0.6666667 
> 
> ## ...and covariance
> (Vl <- covariance(ct))
            1:1         2:1         3:1         1:2         2:2         3:2
1:1  0.35555556 -0.17777778 -0.17777778 -0.17777778  0.08888889  0.08888889
2:1 -0.17777778  0.35555556 -0.17777778  0.08888889 -0.17777778  0.08888889
3:1 -0.17777778 -0.17777778  0.35555556  0.08888889  0.08888889 -0.17777778
1:2 -0.17777778  0.08888889  0.08888889  0.35555556 -0.17777778 -0.17777778
2:2  0.08888889 -0.17777778  0.08888889 -0.17777778  0.35555556 -0.17777778
3:2  0.08888889  0.08888889 -0.17777778 -0.17777778 -0.17777778  0.35555556
1:3 -0.17777778  0.08888889  0.08888889 -0.17777778  0.08888889  0.08888889
2:3  0.08888889 -0.17777778  0.08888889  0.08888889 -0.17777778  0.08888889
3:3  0.08888889  0.08888889 -0.17777778  0.08888889  0.08888889 -0.17777778
            1:3         2:3         3:3
1:1 -0.17777778  0.08888889  0.08888889
2:1  0.08888889 -0.17777778  0.08888889
3:1  0.08888889  0.08888889 -0.17777778
1:2 -0.17777778  0.08888889  0.08888889
2:2  0.08888889 -0.17777778  0.08888889
3:2  0.08888889  0.08888889 -0.17777778
1:3  0.35555556 -0.17777778 -0.17777778
2:3 -0.17777778  0.35555556 -0.17777778
3:3 -0.17777778 -0.17777778  0.35555556
> 
> ## The standardized contingency table...
> (l - El) / sqrt(variance(ct))
          1         2         3
1  0.559017 -1.118034  0.559017
2 -1.118034  2.236068 -1.118034
3  0.559017 -1.118034  0.559017
> 
> ## ...is identical to the standardized linear statistic
> statistic(ct, type = "standardized")
          1         2         3
1  0.559017 -1.118034  0.559017
2 -1.118034  2.236068 -1.118034
3  0.559017 -1.118034  0.559017
> 
> 
> 
> cleanEx()
> nameEx("glioma")
> ### * glioma
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: glioma
> ### Title: Malignant Glioma Pilot Study
> ### Aliases: glioma
> ### Keywords: datasets
> 
> ### ** Examples
> 
> 
>   ### Grade III glioma
>   g3 <- subset(glioma, histology == "Grade3")
> 
>   ### Plot Kaplan-Meier curves
>   layout(matrix(1:2, ncol = 2))
>   plot(survfit(Surv(time, event) ~ group, data = g3),
+        main = "Grade III Glioma", lty = 2:1,
+        ylab = "Probability", xlab = "Survival Time in Month",
+        xlim = c(-2, 72))
>   legend("bottomleft", lty = 2:1, c("Control", "Treated"), bty = "n")
> 
>   ### logrank test
>   surv_test(Surv(time, event) ~ group, data = g3,
+                distribution = "exact")

	Exact 2-Sample Logrank Test

data:  Surv(time, event) by group (Control, RIT)
Z = -2.1711, p-value = 0.02877
alternative hypothesis: true theta is not equal to 1

> 
>   ### Grade IV glioma
>   gbm <- subset(glioma, histology == "GBM")
> 
>   ### Plot Kaplan-Meier curves
>   plot(survfit(Surv(time, event) ~ group, data = gbm),
+        main = "Grade IV Glioma", lty = 2:1,
+        ylab = "Probability", xlab = "Survival Time in Month",
+        xlim = c(-2, 72))
>   legend("topright", lty = 2:1, c("Control", "Treated"), bty = "n")
>   layout(1)
> 
>   ### logrank test
>   surv_test(Surv(time, event) ~ group, data = gbm,
+             distribution = "exact")

	Exact 2-Sample Logrank Test

data:  Surv(time, event) by group (Control, RIT)
Z = -3.2215, p-value = 0.0001588
alternative hypothesis: true theta is not equal to 1

> 
>   ### stratified logrank test
>   surv_test(Surv(time, event) ~ group | histology, data = glioma,
+             distribution = approximate(B = 10000))

	Approximative 2-Sample Logrank Test

data:  Surv(time, event) by
	 group (Control, RIT) 
	 stratified by histology
Z = -3.6704, p-value < 2.2e-16
alternative hypothesis: true theta is not equal to 1

> 
> 
> 
> 
> cleanEx()
> nameEx("hohnloser")
> ### * hohnloser
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: hohnloser
> ### Title: Left ventricular ejection fraction of patients with malignant
> ###   ventricular tachyarrhythmias.
> ### Aliases: hohnloser
> ### Keywords: datasets
> 
> ### ** Examples
> 
> 
>   maxstat_test(Surv(time, event) ~ EF, data = hohnloser)

	Asymptotic Generalized Maximally Selected Statistics

data:  Surv(time, event) by EF
maxT = 3.5647, p-value = 0.004554
alternative hypothesis: two.sided
sample estimates:
  "best" cutpoint: <= 39

> 
> 
> 
> 
> cleanEx()
> nameEx("jobsatisfaction")
> ### * jobsatisfaction
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: jobsatisfaction
> ### Title: Income and Job Satisfaction
> ### Aliases: jobsatisfaction
> ### Keywords: datasets
> 
> ### ** Examples
> 
> 
>   ### Generalized Cochran-Mantel-Haenzel test
>   cmh_test(jobsatisfaction)

	Asymptotic Generalized Cochran-Mantel-Haenszel Test

data:  Job.Satisfaction by
	 Income (<5000, 5000-15000, 15000-25000, >25000) 
	 stratified by Gender
chi-squared = 10.2001, df = 9, p-value = 0.3345

> 
> 
> 
> 
> cleanEx()
> nameEx("mercuryfish")
> ### * mercuryfish
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: mercuryfish
> ### Title: Chromosomal Effects of Mercury Contaminated Fish Consumption
> ### Aliases: mercuryfish
> ### Keywords: datasets
> 
> ### ** Examples
> 
> 
>   ### coherence criterion
>   coherence <- function(data) {
+       x <- as.matrix(data)
+       matrix(apply(x, 1, function(y)
+           sum(colSums(t(x) < y) == ncol(x)) - 
+           sum(colSums(t(x) > y) == ncol(x))), ncol = 1)
+   }
> 
>   ### POSET-test
>   poset <- independence_test(mercury + abnormal + ccells ~ group, data =
+                              mercuryfish, ytrafo = coherence)
> 
>   ### linear statistic (T in Rosenbaum's, 1994, notation)
>   statistic(poset, "linear")
            
control -237
> 
>   ### expectation
>   expectation(poset)
control 
      0 
> 
>   ### variance (there is a typo in Rosenbaum, 1994, page 371, 
>   ### last paragraph Section 2)
>   covariance(poset)
         control
control 3097.954
> 
>   ### the standardized statistic
>   statistic(poset)
  control 
-4.258051 
> 
>   ### and asymptotic p-value
>   pvalue(poset)
[1] 2.062169e-05
> 
>   ### exact p-value
>   independence_test(mercury + abnormal + ccells ~ group, data =
+                     mercuryfish, ytrafo = coherence, distribution = "exact")

	Exact General Independence Test

data:  mercury, abnormal, ccells by group (control, exposed)
Z = -4.2581, p-value = 4.486e-06
alternative hypothesis: two.sided

> 
>   ### multivariate analysis
>   mvtest <- independence_test(mercury + abnormal + ccells ~ group, 
+                               data = mercuryfish)
> 
>   ### global p-value
>   pvalue(mvtest)
[1] 0.007140628
99 percent confidence interval:
 0.006371664 0.007909593 

> 
>   ### single-step adjusted univariate p-value
>   pvalue(mvtest, method = "single-step")
            mercury   abnormal     ccells
control 0.007991569 0.01726738 0.03830126
> 
>   ### step-down adjusted univariate p-value
>   pvalue(mvtest, method = "step-down")
            mercury  abnormal    ccells
control 0.007187993 0.0111254 0.0152947
> 
> 
> 
> 
> cleanEx()
> nameEx("neuropathy")
> ### * neuropathy
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: neuropathy
> ### Title: Acute Painful Diabetic Neuropathy
> ### Aliases: neuropathy
> ### Keywords: datasets
> 
> ### ** Examples
> 
> 
>   ### compare with Table 2 of Conover & Salsburg (1988)
>   oneway_test(pain ~ group, data = neuropathy, alternative = "less",
+               distribution = "exact")

	Exact 2-Sample Permutation Test

data:  pain by group (control, treat)
Z = -1.3191, p-value = 0.09589
alternative hypothesis: true mu is less than 0

> 
>   wilcox_test(pain ~ group, data = neuropathy, alternative = "less",
+               distribution = "exact")

	Exact Wilcoxon-Mann-Whitney Test

data:  pain by group (control, treat)
Z = -0.9817, p-value = 0.1654
alternative hypothesis: true mu is less than 0

> 
>   oneway_test(pain ~ group, data = neuropathy, alternative = "less",
+               distribution = approximate(B = 10000),
+               ytrafo = function(data)
+                   trafo(data, numeric_trafo = consal_trafo))

	Approximative 2-Sample Permutation Test

data:  pain by group (control, treat)
Z = -1.8683, p-value = 0.0284
alternative hypothesis: true mu is less than 0

> 
>   ### maximum-type test for a range of 'a' values
>   it <- independence_test(pain ~ group, data = neuropathy,
+                           alternative = "less",
+                           distribution = approximate(B = 10000),
+                           ytrafo = function(data)
+                               trafo(data, numeric_trafo = function(y)
+                                   consal_trafo(y, a = 2:7)))
>   pvalue(it, method = "single-step")
         a = 2  a = 3  a = 4  a = 5  a = 6  a = 7
control 0.2334 0.1033 0.0653 0.0528 0.0491 0.0497
> 
> 
> 
> 
> cleanEx()
> nameEx("ocarcinoma")
> ### * ocarcinoma
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: ocarcinoma
> ### Title: Ovarian Carcinoma
> ### Aliases: ocarcinoma
> ### Keywords: datasets
> 
> ### ** Examples
> 
> 
>   ### logrank test with exact two-sided p-value
>   lrt <- surv_test(Surv(time, event) ~ stadium, data = ocarcinoma,
+                    distribution = "exact")
> 
>   ### the test statistic
>   statistic(lrt)
      II 
2.337284 
> 
>   ### p-value
>   pvalue(lrt)
[1] 0.01819758
> 
> 
> 
> 
> cleanEx()
> nameEx("photocar")
> ### * photocar
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: photocar
> ### Title: Multiple Dosing Photococarcinogenicity Experiment
> ### Aliases: photocar
> ### Keywords: datasets
> 
> ### ** Examples
> 
> 
>   layout(matrix(1:3, ncol = 3))
>   plot(survfit(Surv(time, event) ~ group, data = photocar), xmax = 50, 
+        lty =  1:3, main = "Survival Time")
>   legend("bottomleft", lty = 1:3, levels(photocar$group), bty = "n")
>   plot(survfit(Surv(dmin, tumor) ~ group, data = photocar), xmax = 50, 
+        lty = 1:3, main = "Time to First Tumor")
>   legend("bottomleft", lty = 1:3, levels(photocar$group), bty = "n")
>   boxplot(ntumor ~ group, data = photocar, main = "Number of Tumors")
> 
>   ### global test (all three responses)
>   fm <- Surv(time, event) + Surv(dmin, tumor) + ntumor ~ group
>   it <- independence_test(fm, data = photocar, 
+                           distribution = approximate(B = 10000))
>   pvalue(it)
[1] 0
99 percent confidence interval:
 0.0000000000 0.0005296914 

> 
>   ### why was the global null hypothesis rejected?
>   statistic(it, "standardized")
  Surv(time, event) Surv(dmin, tumor)     ntumor
A          2.327338          2.178704  0.2642120
B          4.750336          4.106039  0.1509783
C         -7.077674         -6.284743 -0.4151904
>   pvalue(it, "single-step")
  Surv(time, event) Surv(dmin, tumor) ntumor
A             0.129            0.1850  1.000
B             0.000            0.0003  1.000
C             0.000            0.0000  0.999
> 
> 
> 
> 
> cleanEx()
> nameEx("pvalue-methods")
> ### * pvalue-methods
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: pvalue-methods
> ### Title: Computing the p-Value, Mid-p-Value and p-Value Interval
> ### Aliases: pvalue pvalue-methods pvalue,IndependenceTest-method
> ###   pvalue,MaxTypeIndependenceTest-method pvalue,NullDistribution-method
> ###   midpvalue midpvalue-methods midpvalue,IndependenceTest-method
> ###   midpvalue,NullDistribution-method pvalue_interval
> ###   pvalue_interval-methods pvalue_interval,IndependenceTest-method
> ###   pvalue_interval,NullDistribution-method
> ### Keywords: methods htest
> 
> ### ** Examples
> 
> ## Two-sample problem
> dta <- data.frame(
+     y = rnorm(20),
+     x = gl(2, 10)
+ )
> 
> ## Ansari-Bradley test
> (at <- ansari_test(y ~ x, data = dta, distribution = "exact"))

	Exact 2-Sample Ansari-Bradley Test

data:  y by x (1, 2)
Z = 0.4553, p-value = 0.7102
alternative hypothesis: true ratio of scales is not equal to 1

> pvalue(at)
[1] 0.710234
> midpvalue(at)
[1] 0.6564821
> pvalue_interval(at)
      p_0       p_1 
0.6027301 0.7102340 
> 
> ## Bivariate two-sample problem
> dta2 <- data.frame(
+     y1 = rnorm(20) + rep(0:1, each = 10),
+     y2 = rnorm(20),
+     x = gl(2, 10)
+ )
> 
> ## Bivariate Pitman test
> (it <- independence_test(y1 + y2 ~ x, data = dta2,
+                          distribution = approximate(B = 10000)))

	Approximative General Independence Test

data:  y1, y2 by x (1, 2)
maxT = 2.6084, p-value = 0.011
alternative hypothesis: two.sided

> ## Global p-value
> pvalue(it)
[1] 0.011
99 percent confidence interval:
 0.008496613 0.013980169 

> ## Joint distribution single-step p-values
> pvalue(it, method = "single-step")
     y1     y2
1 0.011 0.9998
> ## Joint distribution (free) step-down p-values
> pvalue(it, method = "step-down")
     y1    y2
1 0.011 0.979
> ## Bonferroni single-step p-values
> pvalue(it, method = "single-step", distribution = "marginal")
     y1 y2
1 0.011  1
> ## Sidak single-step p-values
> pvalue(it, method = "single-step", distribution = "marginal", type = "Sidak")
          y1       y2
1 0.01096975 0.999559
> ## Bonferroni (free) step-down p-values
> pvalue(it, method = "step-down", distribution = "marginal")
     y1    y2
1 0.011 0.979
> ## Sidak (free) step-down p-values
> pvalue(it, method = "step-down", distribution = "marginal", type = "Sidak")
          y1    y2
1 0.01096975 0.979
> ## Unadjusted p-values
> pvalue(it, method = "unadjusted")
      y1    y2
1 0.0055 0.979
> 
> 
> ## Length of YOY Gizzard Shad from Kokosing Lake, Ohio, sampled in Summer 1984
> ## Hollander and Wolfe (1999, p. 200, Tab. 6.3)
> yoy <- data.frame(
+     length = c(46, 28, 46, 37, 32, 41, 42, 45, 38, 44,
+                42, 60, 32, 42, 45, 58, 27, 51, 42, 52,
+                38, 33, 26, 25, 28, 28, 26, 27, 27, 27,
+                31, 30, 27, 29, 30, 25, 25, 24, 27, 30),
+     site = gl(4, 10, labels = as.roman(1:4))
+ )
> 
> ## Joint distribution (restricted) step-down p-values for multiple comparisons
> (ot <- oneway_test(length ~ site, data = yoy,
+                    distribution = approximate(B = 10000),
+                    xtrafo = mcp_trafo(site = "Tukey")))

	Approximative K-Sample Permutation Test

data:  length by site (I, II, III, IV)
maxT = 3.953, p-value = 1e-04
alternative hypothesis: two.sided

> pvalue(ot, method = "npmcp")
               
II - I   0.4304
III - I  0.0006
IV - I   0.0002
III - II 0.0002
IV - II  0.0000
IV - III 0.7161
> 
> 
> 
> cleanEx()
> nameEx("rotarod")
> ### * rotarod
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: rotarod
> ### Title: Rotating Rats Data
> ### Aliases: rotarod
> ### Keywords: datasets
> 
> ### ** Examples
> 
> 
>   ### Wilcoxon-Mann-Whitney Rank Sum Test
> 
>   ### one-sided exact (0.0186)
>   wilcox_test(time ~ group, data = rotarod, 
+       alternative = "greater", distribution = "exact")

	Exact Wilcoxon-Mann-Whitney Test

data:  time by group (control, treatment)
Z = 2.4389, p-value = 0.01863
alternative hypothesis: true mu is greater than 0

>   ### two-sided exact (0.0373)
>   wilcox_test(time ~ group, data = rotarod, distribution = "exact")

	Exact Wilcoxon-Mann-Whitney Test

data:  time by group (control, treatment)
Z = 2.4389, p-value = 0.03727
alternative hypothesis: true mu is not equal to 0

>   ### two-sided asymptotical (0.0147)
>   wilcox_test(time ~ group, data = rotarod)

	Asymptotic Wilcoxon-Mann-Whitney Test

data:  time by group (control, treatment)
Z = 2.4389, p-value = 0.01473
alternative hypothesis: true mu is not equal to 0

> 
> 
> 
> 
> cleanEx()
> nameEx("statistic-methods")
> ### * statistic-methods
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: statistic-methods
> ### Title: Computing the Test Statistic and Linear Statistic
> ### Aliases: statistic statistic-methods
> ###   statistic,IndependenceLinearStatistic-method
> ###   statistic,IndependenceTest-method
> ###   statistic,IndependenceTestStatistic-method
> ### Keywords: methods
> 
> ### ** Examples
> 
> dta <- data.frame(
+     y = gl(4, 5),
+     x = gl(5, 4)
+ )
> 
> ## Cochran-Mantel-Haenszel Test
> ct <- cmh_test(y ~ x, data = dta)
> 
> ## Test statistic
> statistic(ct)
[1] 38
> 
> ## The unstandardized linear statistic...
> statistic(ct, type = "linear")
  1 2 3 4
1 4 0 0 0
2 1 3 0 0
3 0 2 2 0
4 0 0 3 1
5 0 0 0 4
> 
> ## ...is identical to the contingency table
> xtabs(~ x + y, data = dta)
   y
x   1 2 3 4
  1 4 0 0 0
  2 1 3 0 0
  3 0 2 2 0
  4 0 0 3 1
  5 0 0 0 4
> 
> ## Illustrating departures from the null hypothesis of independence using the
> ## standardized linear statistic
> statistic(ct, type = "standardized")
          1         2         3         4
1  3.774917 -1.258306 -1.258306 -1.258306
2  0.000000  2.516611 -1.258306 -1.258306
3 -1.258306  1.258306  1.258306 -1.258306
4 -1.258306 -1.258306  2.516611  0.000000
5 -1.258306 -1.258306 -1.258306  3.774917
> 
> 
> 
> cleanEx()
> nameEx("treepipit")
> ### * treepipit
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: treepipit
> ### Title: Tree Pipit (Anthus trivialis) Forest Data
> ### Aliases: treepipit
> ### Keywords: datasets
> 
> ### ** Examples
> 
> 
>   maxstat_test(counts ~ age + coverstorey + coverregen + meanregen +
+                         coniferous + deadtree + cbpiles + ivytree,
+                data = treepipit)

	Asymptotic Generalized Maximally Selected Statistics

data:  counts by
	 age, coverstorey, coverregen, meanregen, coniferous, deadtree, cbpiles, ivytree
maxT = 4.3139, p-value = 0.0006596
alternative hypothesis: two.sided
sample estimates:
  "best" cutpoint: <= 40
       covariable: coverstorey

> 
> 
> 
> 
> ### * <FOOTER>
> ###
> options(digits = 7L)
> base::cat("Time elapsed: ", proc.time() - base::get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  38.82 0.31 39.5 NA NA 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
