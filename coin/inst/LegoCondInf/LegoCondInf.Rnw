\documentclass{article}
\usepackage{amstext}
\usepackage{amsfonts}
\usepackage{hyperref}
\usepackage[round]{natbib}
\usepackage{hyperref}
\usepackage{graphicx}

\newcommand{\Rpackage}[1]{\textit{#1}}
\newcommand{\Robject}[1]{\texttt{#1}}
\newcommand{\Rclass}[1]{\textit{#1}}
\newcommand{\Rcmd}[1]{\texttt{#1}}
\newcommand{\Roperator}[1]{\texttt{#1}}
\newcommand{\Rarg}[1]{\texttt{#1}}
\newcommand{\Rlevel}[1]{\texttt{#1}}

\newcommand{\R}{\mathbb{R} }
\newcommand{\Prob}{\mathbb{P} }
\newcommand{\N}{\mathbb{N} }
\newcommand{\C}{\mathbb{C} }
\newcommand{\V}{\mathbb{V}} %% cal{\mbox{\textnormal{Var}}} }
\newcommand{\E}{\mathbb{E}} %%mathcal{\mbox{\textnormal{E}}} }
\newcommand{\Var}{\mathbb{V}} %%mathcal{\mbox{\textnormal{Var}}} }
\newcommand{\argmin}{\operatorname{argmin}\displaylimits}
\newcommand{\argmax}{\operatorname{argmax}\displaylimits}
\newcommand{\LS}{\mathcal{L}_n}
\newcommand{\TS}{\mathcal{T}_n}
\newcommand{\LSc}{\mathcal{L}_{\text{comb},n}}
\newcommand{\LSbc}{\mathcal{L}^*_{\text{comb},n}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\yn}{y_{\text{new}}}
\newcommand{\z}{\mathbf{z}}
\newcommand{\X}{\mathbf{X}}
\newcommand{\Y}{\mathbf{Y}}
\newcommand{\sX}{\mathcal{X}}
\newcommand{\sY}{\mathcal{Y}}
\newcommand{\T}{\mathbf{T}}
\newcommand{\x}{\mathbf{x}}
\renewcommand{\a}{\mathbf{a}}
\newcommand{\xn}{\mathbf{x}_{\text{new}}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\w}{\mathbf{w}}
\newcommand{\ws}{\mathbf{w}_\cdot}
\renewcommand{\t}{\mathbf{t}}
\newcommand{\M}{\mathbf{M}}
\renewcommand{\vec}{\text{vec}}
\newcommand{\B}{\mathbf{B}}
\newcommand{\K}{\mathbf{K}}
\newcommand{\W}{\mathbf{W}}
\newcommand{\D}{\mathbf{D}}
\newcommand{\I}{\mathbf{I}}
\newcommand{\bS}{\mathbf{S}}
\newcommand{\cellx}{\pi_n[\x]}
\newcommand{\partn}{\pi_n(\mathcal{L}_n)}
\newcommand{\err}{\text{Err}}
\newcommand{\ea}{\widehat{\text{Err}}^{(a)}}
\newcommand{\ecv}{\widehat{\text{Err}}^{(cv1)}}
\newcommand{\ecvten}{\widehat{\text{Err}}^{(cv10)}}
\newcommand{\eone}{\widehat{\text{Err}}^{(1)}}
\newcommand{\eplus}{\widehat{\text{Err}}^{(.632+)}}
\newcommand{\eoob}{\widehat{\text{Err}}^{(oob)}}

\SweaveOpts{engine=R,eps=FALSE}

\hypersetup{%
  pdftitle = {A Lego-System for Conditional Inference},
  pdfsubject = {Manuscript},
  pdfauthor = {Torsten Hothorn, Kurt Hornik,
               Mark van de Wiel and Achim Zeileis},
%% change colorlinks to false for pretty printing
  colorlinks = {true},
  linkcolor = {blue},
  citecolor = {blue},
  urlcolor = {red},
  hyperindex = {true},
  linktocpage = {true},
}

\title{A Lego-System for Conditional Inference}

\author{Torsten Hothorn$^1$, Kurt Hornik$^2$, \\ 
        Mark van de Wiel$^3$ and Achim Zeileis$^2$}
\date{}

\begin{document}

\setkeys{Gin}{width=0.95\textwidth}


\maketitle

\noindent$^1$Institut f\"ur Medizininformatik, Biometrie und Epidemiologie\\
     Friedrich-Alexander-Universit\"at Erlangen-N\"urnberg\\
     Waldstra{\ss}e 6, D-91054 Erlangen, Germany \\
     \texttt{Torsten.Hothorn@R-project.org}
\newline

\noindent$^2$Department f\"ur Statistik und Mathematik,
             Wirtschaftsuniversit\"at Wien \\
       Augasse 2-6, A-1090 Wien, Austria \\
       \texttt{Kurt.Hornik@R-project.org} \\
       \texttt{Achim.Zeileis@R-project.org}
\newline

\noindent$^3$ Department of Mathematics and Computer Science \\
              Eindhoven University of Technology \\
              HG 9.25, P.O. Box 513 \\
              5600 MB Eindhoven, The Netherlands \\
              \texttt{markvdw@win.tue.nl}
\newline

<<setup, echo = FALSE, results = hide>>=
options(width = 60)
require("coin")
require("Biobase")
require("multcomp")
set.seed(290875)
data("alzheimer", package = "coin")
data("photocar", package = "coin")
data("mercuryfish", package = "coin")
@

\section{Introduction}

\section{Conditional Inference}

In the following we assume that we are provided with $n$ observations
\begin{eqnarray*}
(\Y_i, \X_i, b_i), \quad i = 1, \dots, n.
\end{eqnarray*}
The variables $\Y$ and $\X$ from sample spaces $\mathcal{Y}$ and
$\mathcal{X}$ may
be measured at arbitrary scales and may be multivariate as well. In addition
to those measurements a factor $b$ coding blocks may  
be available.

We are interested in testing the null hypothesis of independence of $\Y$ and $\X$
\begin{eqnarray*}
H_0: D(\Y | \X) = D(\Y)
\end{eqnarray*}
against arbitrary alternatives. \cite{StrasserWeber1999} suggest to derive
scalar test statistics for testing $H_0$ from multivariate linear statistics
of the form 
\begin{eqnarray} \label{linstat}
\T = \vec\left(\sum_{i = 1}^n g(\X_i) h(\Y_i, (\Y_1, \dots, \Y_n))^\top\right)
\in \R^{pq}.
\end{eqnarray}
Here, $g: \mathcal{X} \rightarrow \R^{p}$ is a transformation of
the $\X$ measurements and the \emph{influence function}
$h: \mathcal{Y} \times \mathcal{Y}^n \rightarrow
\R^q$ depends on the responses $(\Y_1, \dots, \Y_n)$ in a permutation
symmetric way. We will give specific examples how to choose $g$ and $h$
later on.

The distribution of $\T$  depends on the joint
distribution of $\Y$ and $\X$, which is unknown under almost all practical
circumstances. At least under the null hypothesis one can dispose of this 
dependency by fixing $\X_1, \dots, \X_n$ and conditioning on all possible 
permutations $S$ of the responses $\Y_1, \dots, \Y_n$. 
This principle leads to test procedures known
as \textit{permutation tests}. 

The conditional expectation $\mu \in \R^{pq}$ and covariance
$\Sigma \in \R^{pq \times pq}$ of $\T$ under $H_0$ given
all permutations $\sigma \in S$ of the responses are derived by
\cite{StrasserWeber1999}:
\begin{eqnarray}
\mu = \E(\T | S) & = & \vec \left( \left( \sum_{i = 1}^n g(\X_i) \right)
\E(h | S)^\top \right), \nonumber \\
\Sigma = \V(\T | S) & = &
    \frac{n}{n - 1}  \V(h | S) \otimes
        \left(\sum_i g(\X_i) \otimes  g(\X_i)^\top \right)
\label{expectcovar}
\\
& - & \frac{1}{n - 1}  \V(h | S)  \otimes \left(
        \sum_i g(\X_i) \right) \otimes \left( \sum_i g(\X_i)\right)^\top
\nonumber
\end{eqnarray}
where $\otimes$ denote the Kronecker product. The conditional expectation of the
influence function is
\begin{eqnarray*}
\E(h | S) = n^{-1} \sum_i h(\Y_i, (\Y_1, \dots, \Y_n)) \in
\R^q
\end{eqnarray*}
with corresponding $q \times q$ covariance matrix $\V(h | S)$ given by
\begin{eqnarray*}
n^{-1} \sum_i \left(h(\Y_i, (\Y_1, \dots, \Y_n)) - \E(h | S)
\right) \left(h(\Y_i, (\Y_1, \dots, \Y_n)) - \E(h | S)\right)^\top.
\end{eqnarray*}

Having the conditional expectation and covariance at hand we are able to
standardize a linear statistic $\T \in \R^{pq}$ of the form
(\ref{linstat}). Univariate test statistics~$c$ mapping an observed linear
statistic $\mathbf{t} \in
\R^{pq}$ into the real line can be of arbitrary form.  An obvious choice is
the maximum of the absolute values of the standardized linear statistic
\begin{eqnarray*}
c_\text{max}(\mathbf{t}, \mu, \Sigma)  = \max \left| \frac{\mathbf{t} -
\mu}{\text{diag}(\Sigma)^{1/2}} \right|
\end{eqnarray*}
utilizing the conditional expectation $\mu$ and covariance matrix
$\Sigma$. The application of a quadratic form $c_\text{quad}(\mathbf{t},
\mu,
\Sigma)  =
(\mathbf{t} - \mu) \Sigma^+ (\mathbf{t} - \mu)^\top$ is one alternative,
although
computationally more expensive because the Moore-Penrose
inverse $\Sigma^+$ of $\Sigma$ is involved.

The definition of one- and two-sided $p$-values used for the computations in
the \Rpackage{coin} package is
\begin{eqnarray*}
& & P(c(\T, \mu, \Sigma)\le c(\mathbf{t}, \mu, \Sigma)) \quad \text{(less)} \\  
& & P(c(\T, \mu, \Sigma) \ge c(\mathbf{t}, \mu, \Sigma)) \quad \text{(greater)}\\
& & P(|c(\T, \mu, \Sigma)| \le |c(\mathbf{t}, \mu, \Sigma)|) \quad
\text{(two-sided).}
\end{eqnarray*}
Note that for quadratic forms only two-sided $p$-values are available 
and that in the one-sided case maximum type test statistics are replaced by
\begin{eqnarray*}
\min \left( \frac{\mathbf{t} - \mu}{\text{diag}(\Sigma)^{1/2}} \right)
    \quad \text{(less) and } 
\max \left( \frac{\mathbf{t} - \mu}{\text{diag}(\Sigma)^{1/2}} \right)
    \quad \text{(greater).}
\end{eqnarray*}

The conditional distribution and thus the $p$-value
of the statistics $c(\mathbf{t}, \mu, \Sigma)$ can be
computed in several different ways. For some special forms of the
linear statistic, the exact distribution of the test statistic is trackable.
For two-sample problems, the shift-algorithm by \cite{axact-dist:1986} 
and \cite{exakte-ver:1987} and the split-up algorithm by 
\cite{vdWiel2001} are implemented as part of the package.
Conditional Monte-Carlo procedures can be used to approximate the exact
distribution. \cite{StrasserWeber1999} proved (Theorem 2.3) that the   
conditional distribution of linear statistics $\T$ with conditional    
expectation $\mu$ and covariance $\Sigma$ tends to a multivariate normal
distribution with parameters $\mu$ and $\Sigma$ as $n, s \rightarrow
\infty$. Thus, the asymptotic conditional distribution of test statistics of
the
form $c_\text{max}$ is normal and
can be computed directly in the univariate case ($pq = 1$)
or approximated by means of quasi-randomized Monte-Carlo  
procedures in the multivariate setting \citep{numerical-:1992}. For
quadratic forms
$c_\text{quad}$ which follow a $\chi^2$ distribution with degrees of freedom
given by the rank of $\Sigma$ \citep[Theorem 6.20, ][]{Rasch1995}, exact
probabilities can be computed efficiently.


\section{Lego with \Rpackage{coin}}

\paragraph{Smoking and Alzheimer's Disease}

\cite{SalibHillier1997} report results of a case-control study on
Alzheimer's disease and smoking behaviour of 
$\Sexpr{colSums(margin.table(alzheimer, margin = c(1,2)))["Alzheimer's"]}$
patients suffering from Alzheimer's disease and 
$\Sexpr{sum(colSums(margin.table(alzheimer, margin = c(1,2)))[-1])}$
controls. The data shown in Table~\ref{alzheimertab} have been 
re-constructed from Table~4 in \cite{SalibHillier1997}.

\begin{table}
\begin{center}
\caption{Smoking and Alzheimer's disease. \label{alzheimertab}}
\begin{tabular}{lrrrr} \hline \hline
 & \multicolumn{4}{c}{No. of cigarettes daily} \\
 & None & <10 & 10--20 & >20 \\ \hline
\textit{Female} & & & & \\
<<alzheimer-tab, echo = FALSE, results = tex>>=
x <- t(alzheimer[,,"Female"])
lines <- paste(paste(dimnames(x)$disease, " & "), 
               paste(apply(x, 1, function(l) paste(l, collapse = " & ")), "\\\\"))
for (i in 1:length(lines)) cat(lines[i], "\n")
@

& & & & \\
\textit{Male} & & & & \\
<<alzheimer-tab, echo = FALSE, results = tex>>=
x <- t(alzheimer[,,"Male"])
lines <- paste(paste(dimnames(x)$disease, " & "), 
               paste(apply(x, 1, function(l) paste(l, collapse = " & ")), "\\\\"))
for (i in 1:length(lines)) cat(lines[i], "\n")
@
\hline
\end{tabular}
\end{center}
\end{table}

<<alzheimer-rxc, echo = TRUE>>=
data("alzheimer", package = "coin")
it <- independence_test(alzheimer, teststat = "maxtype")
pvalue(it)
statistic(it, "standardized")
@

<<alzheimer-ordered, echo = TRUE>>=
independence_test(alzheimer, scores = list(smoking = c(0, 5, 15, 25)))
@

\paragraph{Photococarcinogenicity Experiments}

The effect on tumor frequency and latency in photococarcinogenicity
experiments are measured by means of (at least) three response variables:
the survival time, the time to first tumor and the total number of tumors. 
The animals were exposed to different levels of UVR exposure
(group A: topical vehicle and 600 RBUs of UVR, group B: no topical
vehicle and 600 RBUs of UVR and group C: no topical vehicle and
1200 RBUs of UVR). The data are taken from Tables~1 to 3 in 
\cite{Molefeetal2005}.

The main interest is testing the global null of no treatment
effect with respect to survival time, time to first tumor and
number of tumors (Molefe et al., 2005, analyse the detection time
of tumors in addition, this data is not given here). In case the
global null hypothesis can be rejected, the deviations from the
partial hypotheses are of special interest.

<<photocar-data, echo = TRUE>>=
data("photocar", package = "coin")
@

\begin{figure}
\begin{center}
<<photocar-plot, echo = FALSE, fig = TRUE, width = 6, height = 3>>=
layout(matrix(1:3, ncol = 3))
plot(survfit(Surv(time, event) ~ group, data = photocar), xmax = 50,
     lty = 1:3, main = "Survival Time")
     legend("bottomleft", lty = 1:3, levels(photocar$group), bty = "n")
plot(survfit(Surv(dmin, tumor) ~ group, data = photocar), xmax = 50,
     lty = 1:3, main = "Time to First Tumor")
     legend("bottomleft", lty = 1:3, levels(photocar$group), bty = "n")
     boxplot(ntumor ~ group, data = photocar, main = "Number of Tumors")
@
\caption{Kaplan-Meier estimates of time to death and time to first tumor as
         well as boxplots of the total number of tumors in three treatment
         groups.}
\end{center}
\end{figure}

<<photocar-global, echo = TRUE>>=
independence_test(Surv(time, event) + Surv(dmin, tumor) + ntumor ~ group,
                  data = photocar)
@

<<photocar-global, echo = TRUE>>=
it <- independence_test(Surv(time, event) + Surv(dmin, tumor) + ntumor ~ group,
                  data = photocar, distribution = approximate(50000))
pvalue(it, method = "step-down")
@

\paragraph{Contaminated Fish}

Subjects who ate contaminated fish for more than three years in
the 'exposed' group and subjects of a control group are to be
compared. Instead of a multivariate comparison, \cite{Rosenbaum1994a}
applied a coherence criterion. The observations are partially
ordered: an observation is than another when all three variables
('mercury', 'abnormal' and 'ccells') are smaller and a score
reflecting the `ranking' is attached to each observation. The
 distribution of the scores in both groups is to be compared and
the corresponding test is called `POSET-test' (partially ordered
sets).

\begin{figure}
\begin{center}
<<mercuryfish-plot, echo = FALSE, fig = TRUE, width = 6, height = 3>>=
layout(matrix(1:3, ncol = 3))
boxplot(mercury ~ group, data = mercuryfish, main = "Mercury blood level")
boxplot(abnormal ~ group, data = mercuryfish, 
        main = "Abnormal cells", ylab = "Cells in per cent")
boxplot(ccells ~ group, data = mercuryfish, 
        main = "Chomosome aberrations", ylab = "Cells in per cent")
@
\caption{Three response variables}
\end{center}
\end{figure}


<<mercurysfish, echo = TRUE>>=
data("mercuryfish")

coherence <- function(data) {
    x <- as.matrix(data)
    matrix(apply(x, 1, function(y)
           sum(colSums(t(x) < y) == ncol(x)) - 
           sum(colSums(t(x) > y) == ncol(x))), ncol = 1)
}
poset <- independence_test(mercury + abnormal + ccells ~ group, data =
                           mercuryfish, ytrafo = coherence, distribution = exact())
statistic(poset, "linear")
expectation(poset)
variance(poset)
statistic(poset)
pvalue(poset)
@

\begin{figure}
\begin{center}
<<mercuryfish-ppermplot, echo = FALSE, fig = TRUE, height = 4, width = 6>>=
ite <- poset
ita <- independence_test(mercury + abnormal + ccells ~ group, data =     
                           mercuryfish, ytrafo = coherence)
site <- support(ite)
layout(matrix(1:2, ncol = 2))
site <- site[site <= qperm(ite, 0.1) & site > -3]
pite <- sapply(site, function(x) pperm(ite, x))
pita <- sapply(site, function(x) pperm(ita, x))

plot(site, pite, type = "S", ylab = "Distribution", xlab = "Statistic")
lines(site, pita)

site <- support(ite)
site <- site[site >= qperm(ite, 0.9) & site < 3]
pite <- sapply(site, function(x) pperm(ite, x))
pita <- sapply(site, function(x) pperm(ita, x))

plot(site, pite, type = "S", ylab = "Distribution", xlab = "Statistic")
lines(site, pita)
@
\caption{Distribution functions}
\end{center}
\end{figure}


\section{Discussion}

\bibliographystyle{asa}
\bibliography{litdbTH}

\end{document}
