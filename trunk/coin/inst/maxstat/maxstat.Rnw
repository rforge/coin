
<<style, echo = FALSE, results = tex>>=
#style <- "Biometrics"
style <- "Z"
if (style == "Z")
    cat("\\input{headerZ}\n")
if (style == "Biometrics")
    cat("\\input{headerBiometrics}\n")
@

%% need no \usepackage{Sweave}
\SweaveOpts{engine=R, eps=FALSE, echo=FALSE, results=hide}

<<packages>>=
rseed <- 20061103
library("xtable")
library("survival")
@

\section{Introduction} \label{sec:introduction}

Dichotomization of variables measured at higher scale levels 
prior to model building is bad practice 
\citep[][among many others]{Royston2006}.
It will result in loss of power and sophisticated regression
models that adapt itself to the complexity of the regression 
problem at hand are widely available. However, simple regression
models capturing step-shaped relationships between two variables
are valuable for the implementation of scientific results into the 
real world: a one-parameter `good--poor' or `high--low' 
decision rule is attractive to practitioners because of its simplicity.

Such rules of thumb are frequently used to investigate new predictor
variables for patient survival in oncology. \cite{Galon2006} estimate
cutpoints for various characteristics of immune cells within colorectal
tumor samples, such as type, density or location, with respect to their
ability to differentiate between patients with good and poor prognosis.
\cite{Buccisano2006} follow a similar approach, obtaining a threshold for
residual leukemic cells in acute myeloid leukemia patients. The ability for
expression levels of HER2 and co-amplified genes to predict breast cancer
survival is investigated by \cite{Vinatzer2005} utilizing maximally selected
log-rank statistics. Beyond applications in oncology, 
the identification of ecological thresholds is of
increasing interest \citep[see][]{Huggett2005},
e.g., the estimation of cutpoints for habitat factors discriminating between 
ecosystems with low and high abundance of certain indicator species 
\citep{Muller2004}.

Two questions arise from a statistical point of view. In a first step, we
have to make sure that there is some 
relevant association between response and covariate 
and in a second step we want to estimate the `best' cutpoint 
in order to approximate this relationship by a simple model. 
It is convenient to deal with both problems separately. The first problem needs to be addressed by
a formal hypothesis test for the null hypothesis of independence between covariate 
(to be dichotomized)
and response variable. A test with power against shift alternatives, i.e.,
departures from the null hypothesis where the distribution of the response variable 
varies between two groups of observations, is of special interest. 
Once we are able to reject the null hypothesis, we are interested in the 
alternative which lead to the rejection, i.e., want to estimate a cutpoint
or partition.

The first procedure of this kind, utilizing the maximum over multiple $\chi^2$ statistics
for $2 \times 2$ tables, was described by \cite{MillerSiegmund1982}. 
\cite{LausenSchumacher1992} derived an approximation for the asymptotical
distribution of maximally selected rank statistics, extending the area of 
application
to continuous and censored response variables. \cite{Betensky1999} propose
a maximally selected $\chi^2$ test for nominal response variables measured at
$k > 2$ levels and ordered categorical data (maximally selected Cochran-Armitage test).
Finally, \cite{Rabinowitz2000} suggested a maximally selected McNemar's test.
\cite{Lausenetal2004} extended maximally selected rank statistics to more 
than one covariate.

Based on the ideas underlying these established techniques, we suggest a new
generalized class of maximally selected statistics that contains the tests
above as special cases but also allows for direct construction of new test
procedures for less standard test problems. For evaluating the distribution of
the test statistics, a conditional inference approach is adopted by embedding
the tests into the theory of permutation tests of \cite{StrasserWeber1999}.
This permits efficient computation of the complete correlation structure
of the statistics to be maximized. For statistics derived from cutpoints,
the correlations have a special product form which we exploit for evaluation
of the conditional asymptotic distribution: A linear-time algorithm is described
which enables the fast assessment of a large number of cutpoints and
and improves significantly upon approximations for the asymptotic distribution
currently in use. 

Since no assumptions on the scale level of neither the covariate to be dichotomized nor
the response variable are necessary, the class of generalized maximally selected
statistics can not only be used to implement already published procedures but also
extend the methodology to new areas of application. We do so by constructing
a maximally selected log-rank statistic for a censored response partitioned with
respect to two ordered categorical covariates and potential interactions.
This new test is employed to search for a high-risk group determined by the T and N-category
of rectal cancer patients.
%%Although the above sketched procedures are quite popular, most of them rely
%%on rather rough approximations of the reference distribution. The exact conditional 
%%distribution for small samples has been derived for binary response variables 
%%by \cite{Boulesteix2006a,Boulesteix2006b} and an upper bound for the exact $p$-value
%%in the more general case of binary, numeric and censored responses is given
%%by \cite{HothornLausen2003}. The unconditional asymptotic distribution is the distribution
%%of the maximum of the absolute values of standard normal variables with known
%%correlation structure \cite{HothornLausen2003}. For a potentially large number
%%of cutpoints, this distribution is hard to evaluate and approximations, based
%%on the supremum of a Brownian bridge or Ornstein-Uhlenbeck processes and
%%an improved Bonferroni inequality, have to be used. As \cite{HothornLausen2003}, Section 6,
%%point out, those approximations are rather inefficient even for a large number of
%%possible cutpoints and number of observations.

\section{Binary partitions and two-sample statistics} \label{sec:stat}

%% more than binary partitions?
We are provided with independent and identically distributed
observations $(\Y_i, \X_i)$ for $i = 1, \dots, n$ and 
are interested in testing the null hypothesis of independence of the response 
variable $\Y \in \mathcal{Y}$ and and covariate(s) $\X \in \mathcal{X}$
\begin{eqnarray*}
H_0: D(\Y | \X) = D(\Y)
\end{eqnarray*}
against shift alternatives. That is, departures from the null hypothesis
where the distribution of the response variable varies between two groups
of observations are of special interest.
Such binary partitions are defined in advance by $p$ sets $A_1, \dots, A_p$
partitioning the observations into two groups based on the $\X$ 
measurements only. For ordered covariates $\X$, these sets are
typically constructed via cutpoints, i.e., $A_j = \{\X | \X \le \xi_j\}$. Here,
\begin{eqnarray*}
g_j(\X) \quad = \quad \indic(\X \in A_j)
\end{eqnarray*}
denotes the indicator function partitioning the observations
into two groups. Only partitions satisfying a sample size 
constraint $\sum_i g_j(\X_i) \in (n\varepsilon, n - n\varepsilon)$ 
for some fixed $\varepsilon \in (0, 0.5)$ are taken into account. 

The two-sample problem associated with the $j$th binary partition
can be tested using a linear statistic
\begin{eqnarray*}
\T_j \quad = \quad \vec\left(\sum_{i = 1}^n g_j(\X_i) h(\Y_i)^\top\right) 
             \in \R^{q \times 1}
\end{eqnarray*}
where $h: \mathcal{Y} \rightarrow
\R^{q \times 1}$ is an \emph{influence function} applied to the responses.
The function $h(\Y_i) = h(\Y_i, (\Y_1, \dots, \Y_n))$ may depend on the full 
vector of responses $(\Y_1, \dots, \Y_n)$, however only
in a permutation symmetric way, i.e., the value of the
function must not depend on the order in which $\Y_1, \dots, \Y_n$ appear.
For example, with $h$ being a rank transformation for a 
continuous response $\Y$, the linear
statistic $\T_j$ is the sum of the ranks for observations from $A_j$, 
i.e., equals the Wilcoxon-Mann-Whitney statistic. 

A joint linear statistic for all binary partitions is
\begin{eqnarray*}
\T \quad = \quad (\T_1, \dots, \T_p) = \vec\left(\sum_{i = 1}^n g(\X_i) h(\Y_i)^\top\right)
\in \R^{pq \times 1}
\end{eqnarray*}
including all $p$ two-sample partitions, as defined by $g(\X) = (g_1(\X), \dots, g_p(\X))$,
simultaneously for testing $H_0$.

\section{Standardization and estimation} \label{sec:inf}

To assess the partitions/cutpoints on a common scale, the 
corresponding statistics $\T_j$ 
are typically standardized using some location and scale measure. 
Consequently, inference can be based on the maximally selected 
absolute standardized statistics and the best separating partition 
is the one for which the maximum is attained.

For obtaining valid estimates of the mean and covariance of $\T$, 
either a parametric model needs to be specified or non-parametric techniques
can be employed, such as permutation or re-sampling approaches.
Here, we adopt the latter and utilize the permutation test framework
established by \cite{StrasserWeber1999}. Thus, $\T$ is standardized
via its conditional expectation $\mu = \E(\T | S) \in \R^{pq \times 1}$
and covariance $\Sigma = \V(\T | S) \in \R^{pq \times pq}$, derived under
$H_0$ by conditioning on all possible permutations $S$ of the responses
$\Y_1, \dots, \Y_n$. Closed-form expressions for $\mu$ and $\Sigma$ are
available, see \cite{StrasserWeber1999} or \cite{Hothornetal2006}.

%%\begin{eqnarray*}
%%\mu = \E(\T | S) & = & \vec \left( \left( \sum_{i = 1}^n g(\X_i) \right)
%%\E(h | S)^\top \right) \\
%%\Sigma = \V(\T | S) & = &
%%    \frac{n}{n - 1}  \V(h | S) \otimes
%%        \left(\sum_i g(\X_i) \otimes  g(\X_i)^\top \right)
%%\\
%%& - & \frac{1}{n - 1}  \V(h | S)  \otimes \left(
%%        \sum_i g(\X_i) \right) \otimes \left( \sum_i g(\X_i)\right)^\top
%%\nonumber
%%\end{eqnarray*}
%%where $\otimes$ denotes the Kronecker product, and the conditional
%%expectation of the influence function is $\E(h | S) = n^{-1} \sum_i
%%h(\Y_i)$ with corresponding $q \times q$ covariance matrix
%%\begin{eqnarray*}
%%\V(h | S) = n^{-1} \sum_i \left(h(\Y_i) - \E(h | S) \right) \left(h(\Y_i) - \E(h | S)\right)^\top.
%%\end{eqnarray*}

The key step for the construction of a maximally selected 
statistic based on the multivariate
linear statistic $\T$ is its standardization utilizing the
conditional expectation $\mu$ and the diagonal elements of the 
covariance matrix $\Sigma$: the 
maximum of the absolute values of the standardized linear statistic
is used as test statistic
\begin{eqnarray*}
\Tmax  & = & \max \frac{|\T - \mu|}{\sqrt{\text{diag}(\Sigma)}}.
\end{eqnarray*}
When the test statistic is large enough to indicate a deviation 
from the null hypothesis we are interested in determining the
partition with largest standardized statistic: the best
separating partition $A_{j^\star}$ is the one for which the maximum is
attained, i.e., for which the absolute value of the standardized
statistic $\T_{j^\star}$ equals $\Tmax$.
%%\begin{eqnarray*}
%%j^\star = \argmax_j \left|\T_j - \mu_j\right| \times \Sigma_{j,j}^{-1/2}.
%%\end{eqnarray*}
%Z% Either use the same layout as above or simply refer to the argmax
%Z% in the formula above.

\section{Inference}

%% conditional distribution of Tmax: exact, approx, asympt (alles muehsam)
For testing $H_0$ the conditional distribution
of $\Tmax$ given all permutations of the responses is used as reference distribution.
Ideally, we want to compute the exact conditional distribution but this is only
possible in special small sample situations \citep{Boulesteix2006b,Boulesteix2006a}.
Conditional Monte-Carlo methods can be used to approximate the exact conditional
distribution rather easily (evaluate the test statistic $\Tmax$ for randomly 
shuffled responses $\Y$ and compute the proportion of random permutations where 
$\Tmax$ exceeds the test statistic for the permutation $1, \dots, n$). 

Moreover, the exact conditional distribution can be approximated by its
limiting distribution. For $n \rightarrow \infty$ the
distribution of the multivariate linear statistic $\T$ tends to a multivariate 
normal distribution with mean $\mu$ and covariance matrix $\Sigma$ 
\citep[Theorem 3]{StrasserWeber1999}.
Thus, in order to approximate $\Prob(\Tmax > c)$ we have to evaluate
the probability $\Prob(\max(|Z_1|, ..., |Z_{pq}|) > c)$ 
for standard normal random variables $Z_1, \dots, Z_{pq}$ with correlation matrix 
$\Rb = \text{cor}(\Sigma)$ and some $c > 0$. 
%%In fact,
%%this conditional asymptotical distribution coincides with the unconditional asymptotical
%%distribution obtained for maximally selected rank statistics \citep[e.g.,][]{HothornLausen2003}.
The computation of this probability is possible using Quasi-Monte-Carlo methods 
\citep{Genz1992} for moderate dimensions ($pq < 100$, say) but remains infeasible
for higher dimensions.
%%So far, even the asymptotic distribution of $\Tmax$ had to be approximated by
%%approximations of the distribution of the supremum of a Brownian bridge \citep{MillerSiegmund1982} 
%%or Ornstein-Uhlenbeck process \citep{LausenSchumacher1992} over some interval for higher
%%dimensions ($pq > 50$, say). 
%%It should be noted that both approximations ignore the 
%%special correlation structure. \cite{LausenSchumacher1996} proposed to
%%use an improved Bonferroni inequality presented by \cite{Worsley1982} which
%%provides us with an upper bound for $\Prob(\Tmax > c)$ as $n \rightarrow \infty$.
%% (see Appendix).
However, for the most important case of statistics maximally selected
over cutpoints induced by an ordered covariate $\X$ and an ordered or binary response 
$\Y$, the distribution of the maximum of standard normal variables 
can be evaluated numerically by an algorithm with
computing time being linear in the number of cutpoints considered as will be shown 
in the following.

Let $A_j = (-\infty, \xi_j]$ with $\xi_j < \xi_k$ for $1 \le j < k \le p$ 
denote the partitioning sets and let $q = 1$ (i.e., ordered or binary response variable). 
Then, the correlation between $\T_j$ and $\T_k$ is given by
\begin{eqnarray*}
\rho_{j,k} = \frac{\Sigma_{j,k}}{\sqrt{\Sigma_{j,j} \Sigma_{k,k}}} = 
\sqrt{\frac{\left(n - \sum_i g_k(\X_i)\right) \sum_i g_j(\X_i)}
                        {\left(n - \sum_i g_j(\X_i)\right) \sum_i g_k(\X_i)}}.
\end{eqnarray*}
It follows that the correlation matrix is completely determined by the 
subdiagonal elements $\rho_{j,j-1}, j = 2, \dots, p$ and 
it holds that 
\begin{eqnarray*}
\rho_{1,k} = \prod_{j = 2}^k \rho_{j,j-1}.
\end{eqnarray*}
With $\v = (\rho_{1,1}, \dots, \rho_{1,p})$ the lower triangular part of the correlation
matrix $\Rb$ can be written as $\v (1/\v)^\top$ and it follows 
\citep[from][Section 2.1]{Meurant1992} that the
inverse $\Rb^{-1}$ of the correlation matrix is a tridiagonal symmetric band matrix:
\begin{eqnarray*}
\Rb^{-1} = \left( \begin{array}{cccccc}
r_{1,1} & r_{1,2} & 0       & 0 & \dots & 0 \\
r_{1,2} & r_{2,2} & r_{2,3} & 0 & \dots & 0 \\
      0 & r_{2,3} & r_{3,3} & r_{3,4} & \dots & 0  \\
      0 & 0 & r_{3,4} & r_{4,4} & \ddots & 0  \\
\vdots & \vdots   &  \vdots & \ddots & \ddots & \vdots \\
0 & 0 & 0 & 0 & r_{p-1,p-1}& r_{p-1,p} \\
0 & 0 & 0 & 0 & r_{p-1,p} & r_{p,p} 
\end{array}
\right).
\end{eqnarray*}

We have to evaluate the probability that any of $|Z_1|, \dots, |Z_p|$ exceeds
$c > 0$, i.e., the probability
\begin{eqnarray*}
\Prob(\Tmax > c) & = & 1 - 
\frac{1}{\sqrt{|\Rb| (2\pi)^p}} \int\limits_{-c}^{c} 
\exp\left(-\frac{1}{2}\z^\top \Rb^{-1}\z \right) d\z.
\end{eqnarray*}
Because of the special band structure of $\Rb^{-1}$ the quadratic form 
$\z^\top \Rb^{-1}\z$ simplifies to
\begin{eqnarray*}
\z^\top\Rb^{-1}\z = r_{1,1}z_1^2 + 2r_{2,1}z_1z_2 + r_{2,2} z_2^2 + \dots +
2r_{p,p-1} z_pz_{p-1} + r_{p,p}z_p^2.
\end{eqnarray*}
and one can make use of this structure when evaluating the
multivariate normal distribution numerically \citep{GenzKahaner1986}.
With $\phi(z) = \exp\left(-z/2\right)$ we have
\begin{eqnarray*}
& & \int\limits_{-c}^{c} \phi\left(\z^\top \Rb^{-1}\z \right) d\z = \\
& & \int\limits_{-c}^c \phi(r_{1,1}z_1^2)
\int\limits_{-c}^c \phi(2r_{2,1}z_1z_2 + r_{2,2} z_2^2)
\int\limits_{-c}^c \dots
\int\limits_{-c}^c \phi(2r_{p,p-1} z_pz_{p-1} + r_{p,p}z_p^2) d \z
\end{eqnarray*}
and with recursively defined functions $f_j$ ($j = 2, \dots, p + 1$)
\begin{eqnarray*}
f_j(z) & = & \int\limits_{-c}^c \phi\left(2 r_{j, j-1} z \tilde{z} + r_{j,j} \tilde{z}^2\right)
             f_{j+1}(\tilde{z}) d\tilde{z} 
            \quad \forall j = 2, \dots, p \\
f_{p+1}(z) & \equiv & 1
\end{eqnarray*}
the above integral can be re-formulated recursively:
\begin{eqnarray*}
\Prob(\Tmax > c) & = & 1 - \frac{1}{\sqrt{|\Rb| (2\pi)^p}} \int\limits_{-c}^{c} 
\phi\left(\z^\top \Rb^{-1}\z \right) d\z \\
& = & 1 - \frac{1}{\sqrt{|\Rb| (2\pi)^p}}
\int\limits_{-c}^c \phi(r_{1,1}z^2) f_2(z) dz.
\end{eqnarray*}
This integral can be evaluated numerically in $O(p)$ starting with $f_p$
utilizing the techniques described by \cite{Miwa2000}: For a two-dimensional grid
of $z \in [-c, c]$ and $\tilde{z} \in [-c,c]$ values, the function $f_j$ is
evaluated and aggregated over $\tilde{z}$ only, yielding values
of $f_j(z)$ for a grid of $z$ values. 
These values are then re-used when computing $f_{j-1}$. 
%%Using these $p$-values leads to a much
%%more powerful test for larger number of potential cutpoints compared
%%to the best approximation available for this situation so far (see Figure~\ref{approx}).
%%
%%\begin{figure}[h!]
%%\begin{center}
%%\caption{Asymptotic distribution and approximation based on the improved Bonferroni
%%         inequality for $n = 10.000$ observations and $p = 100$ cutpoints. The
%%         test based on the numerically evaluated exact asymptotic distribution
%%         is much more powerful than the test based on the approximation. \label{approx}}
%%<<approx, echo = FALSE, fig = TRUE, width = 7, height = 6>>=
%%load("example/approx.rda")
%%plot(g, pex, type = "l", lty = 1, xlab = expression(c), ylab = expression(P(T[max] <= c)))
%%lines(g, pap, lty = 2)
%%legend("bottomright", lty = c(1, 2), legend = c("Exact Asymptotic", "Improved Bonferroni"), bty = "n")
%%@
%%\end{center}
%%\end{figure}

\section{Applications and illustration}

Maximally selected statistics as described in Section~\ref{sec:stat} can be
applied to covariates $\X$ and responses $\Y$ measured at arbitrary scales; appropriate 
influence functions $h$ for nominal, ordered, numeric, censored and multivariate response
variables are given in the sequel \citep[further details can be found in][]{Hothornetal2006}, 
followed by a description of how to
partition the covariate space for nominal, ordered and multivariate covariates and 
the derivation of a novel maximally selected statistic.

For nominal responses, $h$ is typically a straightforward 
dummy coding of the $k$ factor levels (where it is sufficient
to code for the first $k - 1$ levels only). For ordinal responses,
scores are usually attached to each of the $k$ levels and 
$h$ is the vector of those numeric scores. 
Many possible influence functions are available for discrete or continuous covariates:
The identity transformation is the most natural choice; square root, log, or
rank transformations are possible as well. 
When a numeric response is censored, the log-rank transformation or
Savage scores can be applied.
For a multivariate response, possibly consisting of variables with different scale levels,
the influence function $h$ is a combination of 
influence functions appropriate for any of the univariate response variables
as suggested above. In the presence of a grouping of the observations
into independent blocks, only permutations within blocks are eligible and the
conditional expectation and covariance matrix need to be computed
separately for each block. Therefore, it is easily possible to take a block randomization
scheme in a randomized clinical trial into account. 

The most important situation of a univariate and at least ordinally measured covariate $\X$ leads
to partitions, and thus functions $g_j$, 
induced by cutpoints defined by the realizations $\X_1, \dots, \X_n$. More specifically,
$A_j = (-\infty, \xi_j]$, where $\xi_j$ is the $j$th element of the increasingly sorted unique 
realizations of $\X$ (the sample size constraints apply, of course). Thus, having
identified the best separating partition $A_{j^\star}$, the estimated cutpoint is
$\xi_{j^\star}$. For nominal covariates, all $2^{k-1}$ binary partitions of the $k$ levels 
that meet the sample size constraints are taken into account.
For multiple covariates, we simply look at all binary partitions induced by all covariates
simultaneously. 

This flexible framework can know be utilized to implement 
the conditional versions of already published maximally selected 
statistics and to develop new maximally selected statistics 
for other applications. For binary responses and ordered covariates,
the statistic $\Tmax$ is equivalent to a maximally selected $\chi^2$ statistic 
\citep{MillerSiegmund1982,Koziol1991}. For nominal responses with $k > 2$ levels,
the $\Tmax$ statistic is the maximum over the maximum of 
standardized $k \times 2$ tables, an alternative to maximally selected 
$\chi^2$ statistics for larger tables \citep{Betensky1999}. 
For equidistant scores $1, \dots, k$ attached to an ordered response, 
the statistic $\Tmax$  is equivalent to a maximally selected Cochran-Armitage 
statistic \citep{Betensky1999}, however, no restrictions to the choice of scores apply here.
For numeric or censored responses, $\Tmax$ corresponds to maximally selected rank statistics 
\citep{LausenSchumacher1992}.
In the extreme case of each observation being a block in repeated measurements, 
our test statistic $\Tmax$ for binary responses 
corresponds to maximally selected McNemar's statistics \citep{Rabinowitz2000}.
The special case of maximally selected rank statistics
for multiple covariates has first been studied by \cite{Lausenetal2004}.

<<cao-data>>=
<<tntab, echo = FALSE, results = tex>>=
load("example/maxstat.rda")
tc <- preOP$tclass
nc <- preOP$nclass
levels(tc) <- gsub("p", "yp", levels(tc))
levels(nc) <- gsub("p", "", levels(nc))
tab <- xtabs(~ tc + nc, data = preOP)
names(dimnames(tab)) <- c("T category", "N category")
@

%% nur geordnete zulassen?
\begin{table}
\begin{center}
\caption{Pathological T and N category of $\Sexpr{length(tc)}$ rectal cancer patients 
         treated with a preoperative chemoradiotherapy. \label{tab:tn}}
<<tntab, echo = FALSE, results = tex>>=
tab <- cbind(tab, rowSums(tab))
tab <- rbind(tab, colSums(tab))
if (style == "Z") {
    cat("\\begin{tabular}{|r|rrr|r|} \\hline \n")
    cat(" & \\multicolumn{3}{|c|}{N category} & \\\\ \n")
} else {
    cat("\\begin{tabular}{rrrrr} \n")
    cat(" & \\multicolumn{3}{c}{N category} & \\\\ \n")
}
cat("T category & ", paste(levels(nc), collapse = " & "), " & Total \\\\ \\hline ")
for (i in levels(tc))
cat(i, " & ", paste(tab[i,], collapse = " & "), "\\\\", ifelse(i=="ypT4", "\\hline", ""), "\n")
cat("Total & ", paste(tab[nrow(tab),], collapse = " & "), "\\\\ \\hline", "\n")
cat("\\end{tabular} \n")
@
\end{center}
\end{table}

\setkeys{Gin}{width = 0.7\textwidth}
<<gin, echo = FALSE, results = tex>>=
if (style == "Biometrics")
    cat("\\setkeys{Gin}{width = 0.95\\textwidth}\n")
@
\begin{figure}
\begin{center}
\caption{Survival times of rectum cancer patients in two risk groups identified by a maximally selected log-rank
statistic. \label{fig:maxstat}}
<<maxstat, echo = FALSE, fig = TRUE, width = 7, height = 6>>=
###layout(matrix(1:2, ncol = 2))
###plot(abs(stat), xlab = "Index", ylab = "T")
risk <- as.factor(cutpoint)
plot(survfit(Surv(time, event) ~ risk, data = preOP), xlab = "Time (in months)",
     ylab = "Overall Survival Probability")
text(85, 0.92, paste("N0 or N1 (excluding N1 and ypT4); n =",table(risk)[2]))
text(85, 0.30, paste("N2 and N3 (plus N1 and ypT4); n =", table(risk)[1]))
@
\end{center}
\end{figure}


Going beyond these established techniques is also easily possibly in less
standard situations: New tests can be constructed by choosing an influence function 
$h(\cdot)$ determined by the scale level of the response, and selecting a set of potential
partitions $g(\cdot)$ determined by the available covariates.
As an illustration, we attempt to identify a high- and low-risk groups of
rectal cancer patients---treated with a neo-adjuvant chemoradiotherapy regime---by
differentiating them with respect to their combination of pathological T and N category.
Survival times of $n = \Sexpr{length(tc)}$ patients from the preoperative arm 
of the CAO/ARO/AIO-94 trial \citep{Sauer2004} are under test ($48$ patients with distant
metastases found at surgery were excluded from this analysis). 
Therefore, we propose a new maximally selected statistic for a censored response
and two ordered covariates with potential interactions. Log-rank scores are used
as influence function $h$ for the censored response and the potential partitions
$g$ are constructed from all combinations of the five T and three N categories.
As both categories are ordered, only those partitions are used which are ordered
in T given N and vice versa. This yields 194 %FIXME% can we compute this?
potential partitions, $\Sexpr{length(stat)}$ of which meet the sample size constraints.
The maximum of the absolute values
of the corresponding \Sexpr{length(stat)} standardized statistics is 
\Sexpr{round(teststat, 3)} ($p$-value smaller than $0.0001$). 
The partition chosen by the algorithm identifies all patients with
N category N2 or N3 as being under high risk and almost all patients
from N0 and N1 as being under low risk. As an exception,
a single patient with ypT4 and N1 is assigned to the high risk group as
well---whether or not this decision is sensible or results from random variation
cannot be judged based on one observation alone.
Figure~\ref{fig:maxstat} depicts Kaplan-Meier estimates of the survival
times in the two risk groups.



\section{Discussion}

Maximally selected statistics for the estimation of simple cutpoint models have been
in use since many years. 
%%From an academic point of view, such models are almost always an
%%over-simplification. 
Many researchers appreciate a model that is easy to 
communicate and easy to implement in practical situations. 
Of course, the tradeoff between 
simplicity and accuracy has to be carefully investigated.

The new class of generalized maximally selected statistics based on
the conditional inference framework of \cite{StrasserWeber1999} allows for a unified treatment 
of different kinds of maximally selected statistics. Test procedures from
this framework can be adapted to new test problems by specifying an influence
function $h$, suitable for the scale level of the response, and setting up a set
of potential partitions $g$ determined from the available covariates. As
the number of potential partitions can become large, efficient algorithms are
required for evaluating the distribution of the maximum statistic. For
partitions based on cutpoints, we provide such an algorithm that computes
the asymptotic distribution in linear time by exploiting the special product
structure of the correlation matrix and utilizing numerical integration techniques.

The implementation of (known and newly designed) maximally selected statistics 
only requires the specification of the binary partitions, via a function $g$, and
a problem-specific influence function $h$. Linear statistics $\T$ and the test statistic
$\Tmax$ can be computed in the \textsf{R} system for statistical computing \citep{PKG:R}
utilizing the function \texttt{maxstat\_test()} from the add-on package
\Rpackage{coin} \citep{Hothornetal2006,PKG:coin}.
The distribution of $\Tmax$ can be approximated by its asymptotic distribution or by Monte-Carlo methods 
(also in the presence of a grouping of the observations into independent blocks) readily
available from the same package.

In summary, a unified treatment of maximally selected statistics 
for nominal, ordered, discrete and continuous numeric, censored and
multivariate response variables as well as nominal, ordered and 
multivariate covariates to be dichotomized is now possible 
both conceptually and practically.

%% TODO
%% wollen wir quadratische Formen mit einbauen?
%%c_\text{quad}(\T, \mu, \Sigma)  & = & (\T - \mu) \Sigma^+ (\T - \mu)^\top,
%%involving the Moore-Penrose inverse $\Sigma^+$ of $\Sigma$.
%%
%% kann man nicht eine ganz einfache approximation fuer P(T > max(Z1, ..., Zpq)) herleiten?

<<ack, echo = FALSE, results = tex>>=
if (style == "Z")
    cat("\\input{acknowledgement}\n")
@

\bibliography{maxstat}

%%\section*{Appendix}

%%By the same arguments as used in Section~3.3 of \cite{Worsley1982}, for some $c > 0$
%%\begin{eqnarray*}
%%\Prob(\Tmax > c) = \Prob\left(\bigcup_{j = 1}^p |Z_j| > c\right) \le
%%\sum_{j = 1}^p \Prob(|Z_j| > c) - \sum_{j = 1}^{p - 1} \Prob\left(|Z_j| > c \cap |Z_{j+1}| > c\right)
%%\end{eqnarray*}
%%where computing $\Prob\left(|Z_j| > c \cap |Z_{j+1}| > c\right)$ only requires the evaluation
%%of a bivariate standard normal distribution with correlation $\rho_{j,j+1}$.

\end{document}
